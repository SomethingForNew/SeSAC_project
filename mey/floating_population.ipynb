{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6643a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤ - ê¸¸ë‹¨ìœ„ì¸êµ¬(í–‰ì •ë™) API í˜¸ì¶œ\n",
    "- OA-22178\n",
    "- ê¸°ê°„: 2022ë…„ 1ë¶„ê¸° ~ 2025ë…„ 4ë¶„ê¸°\n",
    "- ì„œë¹„ìŠ¤ëª…: VwsmAdstrdFlorPopltnW\n",
    "+ EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) í¬í•¨ - ìµœì¢… ë²„ì „\n",
    "+ ì´ìƒì¹˜ ìƒì„¸ í™•ì¸ + CSV ì €ì¥\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# Jupyter ì¶œë ¥ ì„¤ì • (ì˜ë¦¼ ë°©ì§€)\n",
    "# ============================================================\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'  # Mac\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ============================================================\n",
    "# ì„¤ì •\n",
    "# ============================================================\n",
    "API_KEY = \"455963584d68666f32367441675145\"\n",
    "SERVICE_NAME = \"VwsmAdstrdFlorPopltnW\"\n",
    "BASE_URL = f\"http://openapi.seoul.go.kr:8088/{API_KEY}/json/{SERVICE_NAME}\"\n",
    "\n",
    "def generate_quarter_codes(start_year=2022, end_year=2025):\n",
    "    codes = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            codes.append(f\"{year}{quarter}\")\n",
    "    return codes\n",
    "\n",
    "QUARTER_CODES = generate_quarter_codes(2022, 2025)\n",
    "print(f\"ìˆ˜ì§‘ ëŒ€ìƒ ë¶„ê¸°: {QUARTER_CODES}\")\n",
    "print(f\"ì´ {len(QUARTER_CODES)}ê°œ ë¶„ê¸°\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# API í˜¸ì¶œ í•¨ìˆ˜ (ì•ˆì •í™” ë²„ì „)\n",
    "# ============================================================\n",
    "def fetch_all_data():\n",
    "    \"\"\"ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ - Jupyter ì•ˆì •í™” ë²„ì „\"\"\"\n",
    "    all_data = []\n",
    "    start = 1\n",
    "    batch_size = 1000\n",
    "    max_retries = 3\n",
    "    max_iterations = 500\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ API - ê¸¸ë‹¨ìœ„ì¸êµ¬(í–‰ì •ë™) ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\")\n",
    "    print(f\"{'='*60}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        end = start + batch_size - 1\n",
    "        url = f\"{BASE_URL}/{start}/{end}\"\n",
    "        \n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(url, timeout=60)\n",
    "                response.raise_for_status()\n",
    "                result = response.json()\n",
    "                \n",
    "                if SERVICE_NAME not in result:\n",
    "                    if 'RESULT' in result:\n",
    "                        error_msg = result.get('RESULT', {})\n",
    "                        print(f\"API ì—ëŸ¬: {error_msg}\")\n",
    "                        if 'INFO-200' in str(error_msg):\n",
    "                            print(\"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ë” ì´ìƒ ë°ì´í„° ì—†ìŒ)\")\n",
    "                            return all_data\n",
    "                    return all_data\n",
    "                \n",
    "                code = result[SERVICE_NAME]['RESULT']['CODE']\n",
    "                if code != 'INFO-000':\n",
    "                    print(f\"API ì‘ë‹µ ì½”ë“œ: {code}\")\n",
    "                    if code == 'INFO-200':\n",
    "                        return all_data\n",
    "                    break\n",
    "                \n",
    "                rows = result[SERVICE_NAME].get('row', [])\n",
    "                if not rows:\n",
    "                    print(\"ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                    return all_data\n",
    "                \n",
    "                all_data.extend(rows)\n",
    "                total_count = result[SERVICE_NAME]['list_total_count']\n",
    "                \n",
    "                print(f\"ìˆ˜ì§‘ ì¤‘: {start:,}~{end:,} / ì „ì²´ {total_count:,}ê±´ (í˜„ì¬ {len(all_data):,}ê±´)\")\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                if len(all_data) >= total_count:\n",
    "                    print(f\"\\nâœ… ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data):,}ê±´\")\n",
    "                    return all_data\n",
    "                \n",
    "                start += batch_size\n",
    "                time.sleep(0.3)\n",
    "                break\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"â° íƒ€ì„ì•„ì›ƒ (ì‹œë„ {retry+1}/{max_retries}): {start}~{end}\")\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"âŒ ìš”ì²­ ì—ëŸ¬ (ì‹œë„ {retry+1}/{max_retries}): {e}\")\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì²˜ë¦¬ ì—ëŸ¬: {e}\")\n",
    "                sys.stdout.flush()\n",
    "                return all_data\n",
    "        \n",
    "        else:\n",
    "            print(f\"âŒ {start}~{end} êµ¬ê°„ ìˆ˜ì§‘ ì‹¤íŒ¨, ë‹¤ìŒìœ¼ë¡œ ì§„í–‰\")\n",
    "            start += batch_size\n",
    "            continue\n",
    "    \n",
    "    print(f\"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({max_iterations}íšŒ)\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def filter_by_quarter(data, quarter_codes):\n",
    "    \"\"\"ê¸°ì¤€ë…„ë¶„ê¸°ì½”ë“œë¡œ í•„í„°ë§\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"\\nì „ì²´ ìˆ˜ì§‘ ë°ì´í„°: {len(df):,}ê±´\")\n",
    "    \n",
    "    df['STDR_YYQU_CD'] = df['STDR_YYQU_CD'].astype(str)\n",
    "    df_filtered = df[df['STDR_YYQU_CD'].isin(quarter_codes)]\n",
    "    print(f\"2022~2025ë…„ ë°ì´í„°: {len(df_filtered):,}ê±´\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ì»¬ëŸ¼ëª… í•œê¸€ ë³€í™˜\n",
    "# ============================================================\n",
    "COLUMN_MAPPING = {\n",
    "    'STDR_YYQU_CD': 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ',\n",
    "    'ADSTRD_CD': 'í–‰ì •ë™_ì½”ë“œ',\n",
    "    'ADSTRD_CD_NM': 'í–‰ì •ë™_ì½”ë“œ_ëª…',\n",
    "    'TOT_FLPOP_CO': 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'ML_FLPOP_CO': 'ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'FML_FLPOP_CO': 'ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_10_FLPOP_CO': 'ì—°ë ¹ëŒ€_10_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_20_FLPOP_CO': 'ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_30_FLPOP_CO': 'ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_40_FLPOP_CO': 'ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_50_FLPOP_CO': 'ì—°ë ¹ëŒ€_50_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'AGRDE_60_ABOVE_FLPOP_CO': 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_00_06_FLPOP_CO': 'ì‹œê°„ëŒ€_00~06_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_06_11_FLPOP_CO': 'ì‹œê°„ëŒ€_06~11_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_11_14_FLPOP_CO': 'ì‹œê°„ëŒ€_11~14_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_14_17_FLPOP_CO': 'ì‹œê°„ëŒ€_14~17_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_17_21_FLPOP_CO': 'ì‹œê°„ëŒ€_17~21_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TMZON_21_24_FLPOP_CO': 'ì‹œê°„ëŒ€_21~24_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'MON_FLPOP_CO': 'ì›”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'TUES_FLPOP_CO': 'í™”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'WED_FLPOP_CO': 'ìˆ˜ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'THUR_FLPOP_CO': 'ëª©ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'FRI_FLPOP_CO': 'ê¸ˆìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'SAT_FLPOP_CO': 'í† ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "    'SUN_FLPOP_CO': 'ì¼ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EDA í•¨ìˆ˜ (ìµœì¢… ë²„ì „ - ì´ìƒì¹˜ ìƒì„¸ + CSV ì €ì¥)\n",
    "# ============================================================\n",
    "def run_eda(df):\n",
    "    \"\"\"\n",
    "    íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA) - ìœ ë™ì¸êµ¬\n",
    "    - ì´ìƒì¹˜ ìƒì„¸ í™•ì¸\n",
    "    - CSV íŒŒì¼ë¡œ ì €ì¥ (ì¶œë ¥ ì˜ë¦¼ ë°©ì§€)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ì‹œì‘ - ìœ ë™ì¸êµ¬\")\n",
    "    print(f\"{'='*60}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 1ë‹¨ê³„: ë°ì´í„° í›‘ì–´ë³´ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 1ë‹¨ê³„: ë°ì´í„° í›‘ì–´ë³´ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n[1-1] ë°ì´í„° í¬ê¸°\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"í–‰ ê°œìˆ˜: {df.shape[0]:,}ê°œ\")\n",
    "    print(f\"ì—´ ê°œìˆ˜: {df.shape[1]}ê°œ\")\n",
    "    \n",
    "    print(\"\\n[1-2] ì»¬ëŸ¼ ëª©ë¡\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2}. {col}\")\n",
    "    \n",
    "    print(\"\\n[1-3] ë°ì´í„° íƒ€ì…\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\n[1-4] ìƒìœ„ 5ê°œ í–‰ ë¯¸ë¦¬ë³´ê¸°\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\n[1-5] ê²°ì¸¡ì¹˜ í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    missing_df = pd.DataFrame({'ê²°ì¸¡ì¹˜ ìˆ˜': missing, 'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': missing_pct})\n",
    "    missing_with_values = missing_df[missing_df['ê²°ì¸¡ì¹˜ ìˆ˜'] > 0]\n",
    "    \n",
    "    if len(missing_with_values) > 0:\n",
    "        print(missing_with_values)\n",
    "        # ê²°ì¸¡ì¹˜ ìƒ˜í”Œ CSV ì €ì¥\n",
    "        for col in missing_with_values.index[:3]:\n",
    "            sample = df[df[col].isnull()][['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', col]]\n",
    "            sample.to_csv(f'eda_ê²°ì¸¡ì¹˜_{col}.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… ê²°ì¸¡ì¹˜ ìƒ˜í”Œ CSV ì €ì¥ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ!\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 2ë‹¨ê³„: ìˆ«ì ìš”ì•½í•˜ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 2ë‹¨ê³„: ìˆ«ì ìš”ì•½í•˜ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n[2-1] ê¸°ì´ˆ í†µê³„ëŸ‰ (ì´_ìœ ë™ì¸êµ¬_ìˆ˜)\")\n",
    "    print(\"-\" * 40)\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        stats = df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].describe()\n",
    "        print(f\"ê°œìˆ˜: {stats['count']:,.0f}ê°œ\")\n",
    "        print(f\"í‰ê· : {stats['mean']:,.0f}ëª…\")\n",
    "        print(f\"ìµœì†Œ: {stats['min']:,.0f}ëª…\")\n",
    "        print(f\"ìµœëŒ€: {stats['max']:,.0f}ëª…\")\n",
    "        print(f\"ì¤‘ì•™ê°’: {stats['50%']:,.0f}ëª…\")\n",
    "        print(f\"í‘œì¤€í¸ì°¨: {stats['std']:,.0f}ëª…\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 3ë‹¨ê³„: ê·¸ë˜í”„ë¡œ ë³´ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 3ë‹¨ê³„: ê·¸ë˜í”„ë¡œ ë³´ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        axes[0, 0].hist(df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / 1e6, bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[0, 0].set_title('ì´ ìœ ë™ì¸êµ¬ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)', fontsize=12)\n",
    "        axes[0, 0].set_xlabel('ìœ ë™ì¸êµ¬ (ë°±ë§Œëª…)')\n",
    "        axes[0, 0].set_ylabel('ë¹ˆë„')\n",
    "    \n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        axes[0, 1].boxplot(df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / 1e6, vert=True)\n",
    "        axes[0, 1].set_title('ì´ ìœ ë™ì¸êµ¬ ë°•ìŠ¤í”Œë¡¯ (ì´ìƒì¹˜ í™•ì¸)', fontsize=12)\n",
    "        axes[0, 1].set_ylabel('ìœ ë™ì¸êµ¬ (ë°±ë§Œëª…)')\n",
    "    \n",
    "    if 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ' in df.columns and 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        quarterly_avg = df.groupby('ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ')['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].mean() / 1e6\n",
    "        quarterly_avg.plot(kind='bar', ax=axes[1, 0], color='steelblue', edgecolor='black')\n",
    "        axes[1, 0].set_title('ë¶„ê¸°ë³„ í‰ê·  ìœ ë™ì¸êµ¬', fontsize=12)\n",
    "        axes[1, 0].set_xlabel('ë¶„ê¸°')\n",
    "        axes[1, 0].set_ylabel('í‰ê·  ìœ ë™ì¸êµ¬ (ë°±ë§Œëª…)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    day_cols = ['ì›”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', 'í™”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', 'ìˆ˜ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', \n",
    "                'ëª©ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', 'ê¸ˆìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', 'í† ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì¼ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜']\n",
    "    day_cols = [col for col in day_cols if col in df.columns]\n",
    "    if day_cols:\n",
    "        day_means = df[day_cols].mean() / 1e6\n",
    "        day_labels = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']\n",
    "        axes[1, 1].bar(day_labels, day_means, color='coral', edgecolor='black')\n",
    "        axes[1, 1].set_title('ìš”ì¼ë³„ í‰ê·  ìœ ë™ì¸êµ¬', fontsize=12)\n",
    "        axes[1, 1].set_xlabel('ìš”ì¼')\n",
    "        axes[1, 1].set_ylabel('í‰ê·  ìœ ë™ì¸êµ¬ (ë°±ë§Œëª…)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('eda_ìœ ë™ì¸êµ¬_ì‹œê°í™”.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… ì‹œê°í™” ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_ì‹œê°í™”.png\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4ë‹¨ê³„: ì´ìƒí•œ ì  ë°œê²¬í•˜ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 4ë‹¨ê³„: ì´ìƒí•œ ì  ë°œê²¬í•˜ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-1. ìœ ë™ì¸êµ¬ê°€ 0ì¸ ë°ì´í„°\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-1] ìœ ë™ì¸êµ¬ê°€ 0ì¸ ë°ì´í„°\")\n",
    "    print(\"-\" * 40)\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        zero_pop = df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] == 0]\n",
    "        print(f\"ìœ ë™ì¸êµ¬ 0 ë°ì´í„°: {len(zero_pop):,}ê±´ ({len(zero_pop)/len(df)*100:.2f}%)\")\n",
    "        \n",
    "        if len(zero_pop) > 0:\n",
    "            # CSV ì €ì¥\n",
    "            zero_pop_save = zero_pop[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']].copy()\n",
    "            zero_pop_save.to_csv('eda_ìœ ë™ì¸êµ¬_0ì¸_ë°ì´í„°.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_0ì¸_ë°ì´í„°.csv ({len(zero_pop)}ê±´)\")\n",
    "            \n",
    "            print(\"\\nğŸ“ ìœ ë™ì¸êµ¬ 0ì´ ë§ì€ í–‰ì •ë™ TOP 5:\")\n",
    "            zero_by_dong = zero_pop['í–‰ì •ë™_ì½”ë“œ_ëª…'].value_counts().head(5)\n",
    "            for dong, cnt in zero_by_dong.items():\n",
    "                print(f\"  - {dong}: {cnt}ê±´\")\n",
    "        else:\n",
    "            print(\"âœ… ìœ ë™ì¸êµ¬ 0ì¸ ë°ì´í„° ì—†ìŒ!\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-2. ìœ ë™ì¸êµ¬ê°€ ìŒìˆ˜ì¸ ë°ì´í„°\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-2] ìœ ë™ì¸êµ¬ê°€ ìŒìˆ˜ì¸ ë°ì´í„°\")\n",
    "    print(\"-\" * 40)\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        negative_pop = df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] < 0]\n",
    "        print(f\"ìœ ë™ì¸êµ¬ ìŒìˆ˜ ë°ì´í„°: {len(negative_pop):,}ê±´\")\n",
    "        \n",
    "        if len(negative_pop) > 0:\n",
    "            negative_pop[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']].to_csv(\n",
    "                'eda_ìœ ë™ì¸êµ¬_ìŒìˆ˜_ë°ì´í„°.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_ìŒìˆ˜_ë°ì´í„°.csv\")\n",
    "        else:\n",
    "            print(\"âœ… ìŒìˆ˜ ìœ ë™ì¸êµ¬ ì—†ìŒ!\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-3. ì¤‘ë³µ ë°ì´í„° í™•ì¸\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-3] ì¤‘ë³µ ë°ì´í„° í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    dup_all = df.duplicated().sum()\n",
    "    print(f\"ì „ì²´ í–‰ ì¤‘ë³µ: {dup_all:,}ê±´\")\n",
    "    \n",
    "    if 'í–‰ì •ë™_ì½”ë“œ' in df.columns and 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ' in df.columns:\n",
    "        dup_key = df.duplicated(subset=['í–‰ì •ë™_ì½”ë“œ', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'], keep=False)\n",
    "        dup_data = df[dup_key]\n",
    "        print(f\"í–‰ì •ë™+ë¶„ê¸° ê¸°ì¤€ ì¤‘ë³µ: {len(dup_data):,}ê±´\")\n",
    "        \n",
    "        if len(dup_data) > 0:\n",
    "            dup_data.to_csv('eda_ìœ ë™ì¸êµ¬_ì¤‘ë³µ_ë°ì´í„°.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_ì¤‘ë³µ_ë°ì´í„°.csv\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-4. ì´ìƒì¹˜ í™•ì¸ (IQR ë°©ì‹) - ìƒì„¸ ë²„ì „\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-4] ì´ìƒì¹˜ í™•ì¸ (ì´_ìœ ë™ì¸êµ¬_ìˆ˜ - IQR ë°©ì‹)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_outliers = 0\n",
    "    outliers_low = pd.DataFrame()\n",
    "    outliers_high = pd.DataFrame()\n",
    "    \n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        q1 = df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].quantile(0.25)\n",
    "        q3 = df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        \n",
    "        print(\"\\nğŸ“ IQR ì´ìƒì¹˜ íŒë³„ ê¸°ì¤€:\")\n",
    "        print(f\"  - Q1 (25%): {q1:,.0f}ëª…\")\n",
    "        print(f\"  - Q3 (75%): {q3:,.0f}ëª…\")\n",
    "        print(f\"  - IQR (Q3-Q1): {iqr:,.0f}ëª…\")\n",
    "        print(f\"  - í•˜í•œ ê²½ê³„ (Q1 - 1.5*IQR): {lower:,.0f}ëª…\")\n",
    "        print(f\"  - ìƒí•œ ê²½ê³„ (Q3 + 1.5*IQR): {upper:,.0f}ëª…\")\n",
    "        print(f\"\\n  â†’ ìœ ë™ì¸êµ¬ < {lower:,.0f}ëª… ì´ë©´ 'í•˜í•œ ì´ìƒì¹˜'\")\n",
    "        print(f\"  â†’ ìœ ë™ì¸êµ¬ > {upper:,.0f}ëª… ì´ë©´ 'ìƒí•œ ì´ìƒì¹˜'\")\n",
    "        \n",
    "        # í•˜í•œ ì´ìƒì¹˜\n",
    "        outliers_low = df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] < lower].copy()\n",
    "        print(f\"\\n[í•˜í•œ ì´ìƒì¹˜] {len(outliers_low):,}ê±´\")\n",
    "        \n",
    "        if len(outliers_low) > 0:\n",
    "            outliers_low_save = outliers_low[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']].copy()\n",
    "            outliers_low_save['ìœ ë™ì¸êµ¬(ë§Œëª…)'] = (outliers_low_save['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / 1e4).round(1)\n",
    "            outliers_low_save = outliers_low_save.sort_values('ì´_ìœ ë™ì¸êµ¬_ìˆ˜')\n",
    "            outliers_low_save.to_csv('eda_ìœ ë™ì¸êµ¬_í•˜í•œì´ìƒì¹˜.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_í•˜í•œì´ìƒì¹˜.csv ({len(outliers_low)}ê±´)\")\n",
    "            \n",
    "            print(\"\\nâš ï¸ í•˜í•œ ì´ìƒì¹˜ TOP 10 (ìœ ë™ì¸êµ¬ ê°€ì¥ ì ì€ ìˆœ):\")\n",
    "            top10_low = outliers_low.nsmallest(10, 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜')[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']]\n",
    "            for idx, row in top10_low.iterrows():\n",
    "                print(f\"  - {row['í–‰ì •ë™_ì½”ë“œ_ëª…']} ({row['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ']}): {row['ì´_ìœ ë™ì¸êµ¬_ìˆ˜']:,.0f}ëª…\")\n",
    "            \n",
    "            print(\"\\nğŸ“ í•˜í•œ ì´ìƒì¹˜ ë¹ˆë„ TOP 10 (ì–´ë–¤ í–‰ì •ë™ì´ ìì£¼ ì´ìƒì¹˜ë¡œ ì¡íˆë‚˜):\")\n",
    "            freq_low = outliers_low.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…').agg(\n",
    "                ì´ìƒì¹˜_íšŸìˆ˜=('ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'count'),\n",
    "                í‰ê· _ìœ ë™ì¸êµ¬=('ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'mean')\n",
    "            ).sort_values('ì´ìƒì¹˜_íšŸìˆ˜', ascending=False).head(10)\n",
    "            freq_low['í‰ê· (ë§Œëª…)'] = (freq_low['í‰ê· _ìœ ë™ì¸êµ¬'] / 1e4).round(1)\n",
    "            for dong, row in freq_low.iterrows():\n",
    "                print(f\"  - {dong}: {row['ì´ìƒì¹˜_íšŸìˆ˜']}ê±´ (í‰ê·  {row['í‰ê· (ë§Œëª…)']}ë§Œëª…)\")\n",
    "        \n",
    "        # ìƒí•œ ì´ìƒì¹˜\n",
    "        outliers_high = df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] > upper].copy()\n",
    "        print(f\"\\n[ìƒí•œ ì´ìƒì¹˜] {len(outliers_high):,}ê±´\")\n",
    "        \n",
    "        if len(outliers_high) > 0:\n",
    "            outliers_high_save = outliers_high[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']].copy()\n",
    "            outliers_high_save['ìœ ë™ì¸êµ¬(ë§Œëª…)'] = (outliers_high_save['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / 1e4).round(1)\n",
    "            outliers_high_save = outliers_high_save.sort_values('ì´_ìœ ë™ì¸êµ¬_ìˆ˜', ascending=False)\n",
    "            outliers_high_save.to_csv('eda_ìœ ë™ì¸êµ¬_ìƒí•œì´ìƒì¹˜.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_ìœ ë™ì¸êµ¬_ìƒí•œì´ìƒì¹˜.csv ({len(outliers_high)}ê±´)\")\n",
    "            \n",
    "            print(\"\\nâš ï¸ ìƒí•œ ì´ìƒì¹˜ TOP 10 (ìœ ë™ì¸êµ¬ ê°€ì¥ ë§ì€ ìˆœ):\")\n",
    "            top10_high = outliers_high.nlargest(10, 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜')[['í–‰ì •ë™_ì½”ë“œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜']]\n",
    "            for idx, row in top10_high.iterrows():\n",
    "                print(f\"  - {row['í–‰ì •ë™_ì½”ë“œ_ëª…']} ({row['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ']}): {row['ì´_ìœ ë™ì¸êµ¬_ìˆ˜']:,.0f}ëª… ({row['ì´_ìœ ë™ì¸êµ¬_ìˆ˜']/1e4:.0f}ë§Œëª…)\")\n",
    "            \n",
    "            print(\"\\nğŸ“ ìƒí•œ ì´ìƒì¹˜ ë¹ˆë„ TOP 10 (ì–´ë–¤ í–‰ì •ë™ì´ ìì£¼ ì´ìƒì¹˜ë¡œ ì¡íˆë‚˜):\")\n",
    "            freq_high = outliers_high.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…').agg(\n",
    "                ì´ìƒì¹˜_íšŸìˆ˜=('ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'count'),\n",
    "                í‰ê· _ìœ ë™ì¸êµ¬=('ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'mean')\n",
    "            ).sort_values('ì´ìƒì¹˜_íšŸìˆ˜', ascending=False).head(10)\n",
    "            freq_high['í‰ê· (ë§Œëª…)'] = (freq_high['í‰ê· _ìœ ë™ì¸êµ¬'] / 1e4).round(1)\n",
    "            for dong, row in freq_high.iterrows():\n",
    "                print(f\"  - {dong}: {row['ì´ìƒì¹˜_íšŸìˆ˜']}ê±´ (í‰ê·  {row['í‰ê· (ë§Œëª…)']}ë§Œëª…)\")\n",
    "        \n",
    "        total_outliers = len(outliers_low) + len(outliers_high)\n",
    "        print(f\"\\nğŸ“Š ì´ìƒì¹˜ ìš”ì•½:\")\n",
    "        print(f\"  - í•˜í•œ ì´ìƒì¹˜: {len(outliers_low):,}ê±´\")\n",
    "        print(f\"  - ìƒí•œ ì´ìƒì¹˜: {len(outliers_high):,}ê±´\")\n",
    "        print(f\"  - ì „ì²´ ì´ìƒì¹˜: {total_outliers:,}ê±´ ({total_outliers/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-5. ë¶„ê¸°ë³„ ë°ì´í„° ê±´ìˆ˜ í™•ì¸\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-5] ë¶„ê¸°ë³„ ë°ì´í„° ê±´ìˆ˜ í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    if 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ' in df.columns:\n",
    "        quarter_counts = df.groupby('ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ').size().sort_index()\n",
    "        print(quarter_counts)\n",
    "        \n",
    "        avg_count = quarter_counts.mean()\n",
    "        print(f\"\\në¶„ê¸° í‰ê·  ë°ì´í„° ìˆ˜: {avg_count:.0f}ê±´\")\n",
    "        \n",
    "        abnormal_quarters = quarter_counts[abs(quarter_counts - avg_count) > avg_count * 0.2]\n",
    "        if len(abnormal_quarters) > 0:\n",
    "            print(\"\\nâš ï¸ í‰ê·  ëŒ€ë¹„ Â±20% ì´ìƒ ì°¨ì´ë‚˜ëŠ” ë¶„ê¸°:\")\n",
    "            for q, cnt in abnormal_quarters.items():\n",
    "                diff_pct = (cnt - avg_count) / avg_count * 100\n",
    "                print(f\"  - {q}: {cnt}ê±´ ({diff_pct:+.1f}%)\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # EDA ìš”ì•½\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA ìš”ì•½ - ìœ ë™ì¸êµ¬\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ì´ ë°ì´í„°: {len(df):,}ê±´\")\n",
    "    print(f\"í–‰ì •ë™ ìˆ˜: {df['í–‰ì •ë™_ì½”ë“œ_ëª…'].nunique()}ê°œ\")\n",
    "    print(f\"ë¶„ê¸° ìˆ˜: {df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "    \n",
    "    issues = []\n",
    "    if len(missing_with_values) > 0:\n",
    "        issues.append(f\"ê²°ì¸¡ì¹˜ ìˆìŒ\")\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns and len(df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] == 0]) > 0:\n",
    "        issues.append(f\"ìœ ë™ì¸êµ¬ 0: {len(df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] == 0]):,}ê±´\")\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns and len(df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] < 0]) > 0:\n",
    "        issues.append(f\"ìœ ë™ì¸êµ¬ ìŒìˆ˜: {len(df[df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] < 0]):,}ê±´\")\n",
    "    if dup_all > 0:\n",
    "        issues.append(f\"ì¤‘ë³µ í–‰: {dup_all:,}ê±´\")\n",
    "    if 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜' in df.columns:\n",
    "        issues.append(f\"ì´ìƒì¹˜: {total_outliers:,}ê±´\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nâœ… íŠ¹ë³„í•œ ì´ìŠˆ ì—†ìŒ!\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì €ì¥ëœ CSV íŒŒì¼ ëª©ë¡:\")\n",
    "    print(\"  - eda_ìœ ë™ì¸êµ¬_í•˜í•œì´ìƒì¹˜.csv (ìœ ë™ì¸êµ¬ ë„ˆë¬´ ì ì€ í–‰ì •ë™)\")\n",
    "    print(\"  - eda_ìœ ë™ì¸êµ¬_ìƒí•œì´ìƒì¹˜.csv (ìœ ë™ì¸êµ¬ ë„ˆë¬´ ë§ì€ í–‰ì •ë™)\")\n",
    "    if len(zero_pop) > 0:\n",
    "        print(\"  - eda_ìœ ë™ì¸êµ¬_0ì¸_ë°ì´í„°.csv\")\n",
    "    if len(negative_pop) > 0:\n",
    "        print(\"  - eda_ìœ ë™ì¸êµ¬_ìŒìˆ˜_ë°ì´í„°.csv\")\n",
    "    if len(dup_data) > 0:\n",
    "        print(\"  - eda_ìœ ë™ì¸êµ¬_ì¤‘ë³µ_ë°ì´í„°.csv\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA ì™„ë£Œ!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ë©”ì¸ ì‹¤í–‰\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ í”„ë¡œê·¸ë¨ ì‹œì‘\")\n",
    "    print(f\"í˜„ì¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    if API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "        print(\"âš ï¸  API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!\")\n",
    "        API_KEY = \"sample\"\n",
    "        BASE_URL = f\"http://openapi.seoul.go.kr:8088/{API_KEY}/json/{SERVICE_NAME}\"\n",
    "    \n",
    "    raw_data = fetch_all_data()\n",
    "    \n",
    "    if raw_data:\n",
    "        df_result = filter_by_quarter(raw_data, QUARTER_CODES)\n",
    "        \n",
    "        if len(df_result) > 0:\n",
    "            existing_cols = {k: v for k, v in COLUMN_MAPPING.items() if k in df_result.columns}\n",
    "            df_result = df_result.rename(columns=existing_cols)\n",
    "            \n",
    "            numeric_cols = [col for col in df_result.columns if 'ìœ ë™ì¸êµ¬' in col]\n",
    "            for col in numeric_cols:\n",
    "                df_result[col] = pd.to_numeric(df_result[col], errors='coerce')\n",
    "            \n",
    "            output_file = \"ì„œìš¸ì‹œ_ê¸¸ë‹¨ìœ„ì¸êµ¬_í–‰ì •ë™_2022_2025.csv\"\n",
    "            df_result.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"ì´ ë°ì´í„° ìˆ˜: {len(df_result):,}ê±´\")\n",
    "            print(f\"í–‰ì •ë™ ìˆ˜: {df_result['í–‰ì •ë™_ì½”ë“œ_ëª…'].nunique()}ê°œ\")\n",
    "            print(f\"ë¶„ê¸° ìˆ˜: {df_result['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "            \n",
    "            df_result = run_eda(df_result)\n",
    "            \n",
    "        else:\n",
    "            print(\"2022~2025ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "    \n",
    "    print(f\"\\nğŸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

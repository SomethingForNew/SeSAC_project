{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ac756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìˆ˜ì§‘ ëŒ€ìƒ ë¶„ê¸°: ['20221', '20222', '20223', '20224', '20231', '20232', '20233', '20234', '20241', '20242', '20243', '20244', '20251', '20252', '20253', '20254']\n",
      "ì´ 16ê°œ ë¶„ê¸°\n",
      "í•„í„°ë§ ì—…ì¢…: í¸ì˜ì  (CS300002)\n",
      "ğŸš€ í”„ë¡œê·¸ë¨ ì‹œì‘\n",
      "í˜„ì¬ ì‹œê°„: 2026-01-25 15:49:12\n",
      "âš ï¸ ë°ì´í„°ê°€ 57ë§Œê±´ì´ë¼ ìˆ˜ì§‘ì— 10~15ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   (í¸ì˜ì ë§Œ í•„í„°ë§í•˜ë©´ ì•½ 1~2ë§Œê±´ ì˜ˆìƒ)\n",
      "\n",
      "============================================================\n",
      "ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ API - ìƒê¶Œë³„ ë§¤ì¶œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤ - ìƒê¶Œë³„ ë§¤ì¶œ ì •ë³´ API í˜¸ì¶œ\n",
    "- OA-15572\n",
    "- ì„œë¹„ìŠ¤ëª…: VwsmTrdarSelngQq\n",
    "- í¸ì˜ì (CS300002)ë§Œ í•„í„°ë§\n",
    "- ê¸°ì¤€ë…„ë¶„ê¸° + ìƒê¶Œìœ í˜•ë³„ ë§¤ì¶œ ì§‘ê³„\n",
    "+ EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) í¬í•¨\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# Jupyter ì¶œë ¥ ì„¤ì • (ì˜ë¦¼ ë°©ì§€)\n",
    "# ============================================================\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'  # Mac\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ============================================================\n",
    "# ì„¤ì •\n",
    "# ============================================================\n",
    "API_KEY = \"455963584d68666f32367441675145\"\n",
    "SERVICE_NAME = \"VwsmTrdarSelngQq\"\n",
    "BASE_URL = f\"http://openapi.seoul.go.kr:8088/{API_KEY}/json/{SERVICE_NAME}\"\n",
    "\n",
    "# í¸ì˜ì  ì—…ì¢…ì½”ë“œ\n",
    "CONVENIENCE_STORE_CODE = \"CS300002\"\n",
    "\n",
    "def generate_quarter_codes(start_year=2022, end_year=2025):\n",
    "    codes = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            codes.append(f\"{year}{quarter}\")\n",
    "    return codes\n",
    "\n",
    "QUARTER_CODES = generate_quarter_codes(2022, 2025)\n",
    "print(f\"ìˆ˜ì§‘ ëŒ€ìƒ ë¶„ê¸°: {QUARTER_CODES}\")\n",
    "print(f\"ì´ {len(QUARTER_CODES)}ê°œ ë¶„ê¸°\")\n",
    "print(f\"í•„í„°ë§ ì—…ì¢…: í¸ì˜ì  ({CONVENIENCE_STORE_CODE})\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# API í˜¸ì¶œ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def fetch_all_data():\n",
    "    \"\"\"ì „ì²´ ìƒê¶Œë³„ ë§¤ì¶œ ë°ì´í„° ìˆ˜ì§‘\"\"\"\n",
    "    all_data = []\n",
    "    start = 1\n",
    "    batch_size = 1000\n",
    "    max_retries = 3\n",
    "    max_iterations = 1000\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ API - ìƒê¶Œë³„ ë§¤ì¶œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\")\n",
    "    print(f\"{'='*60}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        end = start + batch_size - 1\n",
    "        url = f\"{BASE_URL}/{start}/{end}\"\n",
    "        \n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(url, timeout=60)\n",
    "                response.raise_for_status()\n",
    "                result = response.json()\n",
    "                \n",
    "                if SERVICE_NAME not in result:\n",
    "                    if 'RESULT' in result:\n",
    "                        error_msg = result.get('RESULT', {})\n",
    "                        print(f\"API ì—ëŸ¬: {error_msg}\")\n",
    "                        if 'INFO-200' in str(error_msg):\n",
    "                            print(\"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ë” ì´ìƒ ë°ì´í„° ì—†ìŒ)\")\n",
    "                            return all_data\n",
    "                    return all_data\n",
    "                \n",
    "                code = result[SERVICE_NAME]['RESULT']['CODE']\n",
    "                if code != 'INFO-000':\n",
    "                    print(f\"API ì‘ë‹µ ì½”ë“œ: {code}\")\n",
    "                    if code == 'INFO-200':\n",
    "                        return all_data\n",
    "                    break\n",
    "                \n",
    "                rows = result[SERVICE_NAME].get('row', [])\n",
    "                if not rows:\n",
    "                    print(\"ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                    return all_data\n",
    "                \n",
    "                all_data.extend(rows)\n",
    "                total_count = result[SERVICE_NAME]['list_total_count']\n",
    "                \n",
    "                if len(all_data) % 10000 < batch_size:\n",
    "                    print(f\"ìˆ˜ì§‘ ì¤‘: {start:,}~{end:,} / ì „ì²´ {total_count:,}ê±´ (í˜„ì¬ {len(all_data):,}ê±´)\")\n",
    "                    sys.stdout.flush()\n",
    "                \n",
    "                if len(all_data) >= total_count:\n",
    "                    print(f\"\\nâœ… ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data):,}ê±´\")\n",
    "                    return all_data\n",
    "                \n",
    "                start += batch_size\n",
    "                time.sleep(0.2)\n",
    "                break\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"â° íƒ€ì„ì•„ì›ƒ (ì‹œë„ {retry+1}/{max_retries}): {start}~{end}\")\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"âŒ ìš”ì²­ ì—ëŸ¬ (ì‹œë„ {retry+1}/{max_retries}): {e}\")\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì²˜ë¦¬ ì—ëŸ¬: {e}\")\n",
    "                sys.stdout.flush()\n",
    "                return all_data\n",
    "        \n",
    "        else:\n",
    "            print(f\"âŒ {start}~{end} êµ¬ê°„ ìˆ˜ì§‘ ì‹¤íŒ¨, ë‹¤ìŒìœ¼ë¡œ ì§„í–‰\")\n",
    "            start += batch_size\n",
    "            continue\n",
    "    \n",
    "    print(f\"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({max_iterations}íšŒ)\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def filter_convenience_store(data, quarter_codes):\n",
    "    \"\"\"í¸ì˜ì ë§Œ í•„í„°ë§ + ê¸°ì¤€ë…„ë¶„ê¸° í•„í„°ë§\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"\\nì „ì²´ ìˆ˜ì§‘ ë°ì´í„°: {len(df):,}ê±´\")\n",
    "    \n",
    "    # ë¶„ê¸° í•„í„°ë§\n",
    "    df['STDR_YYQU_CD'] = df['STDR_YYQU_CD'].astype(str)\n",
    "    df = df[df['STDR_YYQU_CD'].isin(quarter_codes)]\n",
    "    print(f\"2022~2025ë…„ ë°ì´í„°: {len(df):,}ê±´\")\n",
    "    \n",
    "    # í¸ì˜ì  í•„í„°ë§\n",
    "    df = df[df['SVC_INDUTY_CD'] == CONVENIENCE_STORE_CODE]\n",
    "    print(f\"í¸ì˜ì  ë°ì´í„°: {len(df):,}ê±´\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ì»¬ëŸ¼ëª… í•œê¸€ ë³€í™˜\n",
    "# ============================================================\n",
    "COLUMN_MAPPING = {\n",
    "    'STDR_YYQU_CD': 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ',\n",
    "    'TRDAR_SE_CD': 'ìƒê¶Œêµ¬ë¶„_ì½”ë“œ',\n",
    "    'TRDAR_SE_CD_NM': 'ìƒê¶Œêµ¬ë¶„_ëª…',\n",
    "    'TRDAR_CD': 'ìƒê¶Œ_ì½”ë“œ',\n",
    "    'TRDAR_CD_NM': 'ìƒê¶Œ_ëª…',\n",
    "    'SVC_INDUTY_CD': 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ',\n",
    "    'SVC_INDUTY_CD_NM': 'ì„œë¹„ìŠ¤_ì—…ì¢…_ëª…',\n",
    "    'THSMON_SELNG_AMT': 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'THSMON_SELNG_CO': 'ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜',\n",
    "    'MDWK_SELNG_AMT': 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'WKEND_SELNG_AMT': 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'MON_SELNG_AMT': 'ì›”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'TUES_SELNG_AMT': 'í™”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'WED_SELNG_AMT': 'ìˆ˜ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'THUR_SELNG_AMT': 'ëª©ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'FRI_SELNG_AMT': 'ê¸ˆìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'SAT_SELNG_AMT': 'í† ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'SUN_SELNG_AMT': 'ì¼ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'ML_SELNG_AMT': 'ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "    'FML_SELNG_AMT': 'ì—¬ì„±_ë§¤ì¶œ_ê¸ˆì•¡',\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ê¸°ì¤€ë…„ë¶„ê¸° + ìƒê¶Œìœ í˜•ë³„ ì§‘ê³„ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def aggregate_by_quarter_type(df):\n",
    "    \"\"\"\n",
    "    ê¸°ì¤€ë…„ë¶„ê¸° + ìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ë§¤ì¶œ ì§‘ê³„\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š ê¸°ì¤€ë…„ë¶„ê¸° + ìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ë§¤ì¶œ ì§‘ê³„\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    agg_df = df.groupby(['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ëª…']).agg(\n",
    "        ì´_ë§¤ì¶œ_ê¸ˆì•¡=('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'sum'),\n",
    "        ì´_ë§¤ì¶œ_ê±´ìˆ˜=('ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'sum'),\n",
    "        í‰ê· _ë§¤ì¶œ_ê¸ˆì•¡=('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'mean'),\n",
    "        ìƒê¶Œ_ìˆ˜=('ìƒê¶Œ_ì½”ë“œ', 'nunique'),\n",
    "        ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡=('ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'sum'),\n",
    "        ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡=('ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡', 'sum'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    agg_df['ê±´ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡'] = (agg_df['ì´_ë§¤ì¶œ_ê¸ˆì•¡'] / agg_df['ì´_ë§¤ì¶œ_ê±´ìˆ˜']).round(0)\n",
    "    \n",
    "    print(f\"ì§‘ê³„ ì™„ë£Œ: {len(agg_df)}í–‰ (ë¶„ê¸° x ìƒê¶Œìœ í˜•)\")\n",
    "    \n",
    "    return agg_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EDA í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def run_eda(df_raw, df_agg):\n",
    "    \"\"\"\n",
    "    íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA) - í¸ì˜ì  ë§¤ì¶œ\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ì‹œì‘ - í¸ì˜ì  ë§¤ì¶œ\")\n",
    "    print(f\"{'='*60}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 1ë‹¨ê³„: ë°ì´í„° í›‘ì–´ë³´ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 1ë‹¨ê³„: ë°ì´í„° í›‘ì–´ë³´ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n[1-1] ë°ì´í„° í¬ê¸°\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ì „ì²´ ë°ì´í„°: {len(df_raw):,}ê±´\")\n",
    "    print(f\"ë¶„ê¸° ìˆ˜: {df_raw['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "    print(f\"ìƒê¶Œ ìˆ˜: {df_raw['ìƒê¶Œ_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "    \n",
    "    print(\"\\n[1-2] ìƒê¶Œìœ í˜•ë³„ ë°ì´í„° ê±´ìˆ˜\")\n",
    "    print(\"-\" * 40)\n",
    "    ìƒê¶Œìœ í˜•_ë¶„í¬ = df_raw['ìƒê¶Œêµ¬ë¶„_ëª…'].value_counts()\n",
    "    for ìœ í˜•, ê°œìˆ˜ in ìƒê¶Œìœ í˜•_ë¶„í¬.items():\n",
    "        print(f\"  - {ìœ í˜•}: {ê°œìˆ˜:,}ê±´ ({ê°œìˆ˜/len(df_raw)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n[1-3] ìƒìœ„ 5ê°œ í–‰ ë¯¸ë¦¬ë³´ê¸°\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df_raw[['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ëª…', 'ìƒê¶Œ_ëª…', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']].head())\n",
    "    \n",
    "    print(\"\\n[1-4] ê²°ì¸¡ì¹˜ í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    missing = df_raw.isnull().sum()\n",
    "    missing_with_values = missing[missing > 0]\n",
    "    if len(missing_with_values) > 0:\n",
    "        print(missing_with_values)\n",
    "    else:\n",
    "        print(\"âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ!\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 2ë‹¨ê³„: ìˆ«ì ìš”ì•½í•˜ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 2ë‹¨ê³„: ìˆ«ì ìš”ì•½í•˜ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n[2-1] ì§‘ê³„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df_agg.head(10))\n",
    "    \n",
    "    print(\"\\n[2-2] ìƒê¶Œìœ í˜•ë³„ ì´ ë§¤ì¶œ (ì „ì²´ ê¸°ê°„)\")\n",
    "    print(\"-\" * 40)\n",
    "    type_total = df_agg.groupby('ìƒê¶Œêµ¬ë¶„_ëª…')['ì´_ë§¤ì¶œ_ê¸ˆì•¡'].sum().sort_values(ascending=False)\n",
    "    for ìœ í˜•, ê¸ˆì•¡ in type_total.items():\n",
    "        print(f\"  - {ìœ í˜•}: {ê¸ˆì•¡/1e12:.2f}ì¡°ì›\")\n",
    "    \n",
    "    print(\"\\n[2-3] ê¸°ì´ˆ í†µê³„ëŸ‰ (ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡)\")\n",
    "    print(\"-\" * 40)\n",
    "    stats = df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].describe()\n",
    "    print(f\"ê°œìˆ˜: {stats['count']:,.0f}ê±´\")\n",
    "    print(f\"í‰ê· : {stats['mean']/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"ìµœì†Œ: {stats['min']/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"ìµœëŒ€: {stats['max']/1e9:,.2f}ì‹­ì–µì›\")\n",
    "    print(f\"ì¤‘ì•™ê°’: {stats['50%']/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 3ë‹¨ê³„: ê·¸ë˜í”„ë¡œ ë³´ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 3ë‹¨ê³„: ê·¸ë˜í”„ë¡œ ë³´ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 3-1. ìƒê¶Œìœ í˜•ë³„ ì´ ë§¤ì¶œ (íŒŒì´ì°¨íŠ¸)\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "    axes[0, 0].pie(type_total.values, labels=type_total.index, autopct='%1.1f%%', colors=colors[:len(type_total)])\n",
    "    axes[0, 0].set_title('ìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ì´ ë§¤ì¶œ ë¹„ì¤‘', fontsize=12)\n",
    "    \n",
    "    # 3-2. ë¶„ê¸°ë³„ ì´ ë§¤ì¶œ ì¶”ì´\n",
    "    quarterly = df_agg.groupby('ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ')['ì´_ë§¤ì¶œ_ê¸ˆì•¡'].sum() / 1e12\n",
    "    quarterly.plot(kind='bar', ax=axes[0, 1], color='steelblue', edgecolor='black')\n",
    "    axes[0, 1].set_title('ë¶„ê¸°ë³„ í¸ì˜ì  ì´ ë§¤ì¶œ ì¶”ì´', fontsize=12)\n",
    "    axes[0, 1].set_xlabel('ë¶„ê¸°')\n",
    "    axes[0, 1].set_ylabel('ì´ ë§¤ì¶œ (ì¡°ì›)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3-3. ìƒê¶Œìœ í˜•ë³„ ë¶„ê¸° ë§¤ì¶œ ì¶”ì´ (ì„ ê·¸ë˜í”„)\n",
    "    for ìœ í˜• in df_agg['ìƒê¶Œêµ¬ë¶„_ëª…'].unique():\n",
    "        data = df_agg[df_agg['ìƒê¶Œêµ¬ë¶„_ëª…'] == ìœ í˜•].set_index('ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ')['ì´_ë§¤ì¶œ_ê¸ˆì•¡'] / 1e12\n",
    "        axes[1, 0].plot(data.index, data.values, marker='o', label=ìœ í˜•)\n",
    "    axes[1, 0].set_title('ìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ë¶„ê¸° ë§¤ì¶œ ì¶”ì´', fontsize=12)\n",
    "    axes[1, 0].set_xlabel('ë¶„ê¸°')\n",
    "    axes[1, 0].set_ylabel('ì´ ë§¤ì¶œ (ì¡°ì›)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3-4. ë§¤ì¶œ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯ - ìƒê¶Œìœ í˜•ë³„)\n",
    "    df_raw.boxplot(column='ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', by='ìƒê¶Œêµ¬ë¶„_ëª…', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('ìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ë§¤ì¶œ ë¶„í¬', fontsize=12)\n",
    "    axes[1, 1].set_xlabel('ìƒê¶Œìœ í˜•')\n",
    "    axes[1, 1].set_ylabel('ë§¤ì¶œ (ì›)')\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('eda_í¸ì˜ì ë§¤ì¶œ_ì‹œê°í™”.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… ì‹œê°í™” ì €ì¥ ì™„ë£Œ: eda_í¸ì˜ì ë§¤ì¶œ_ì‹œê°í™”.png\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4ë‹¨ê³„: ì´ìƒí•œ ì  ë°œê²¬í•˜ê¸°\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Œ 4ë‹¨ê³„: ì´ìƒí•œ ì  ë°œê²¬í•˜ê¸°\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    zero_sales = pd.DataFrame()\n",
    "    negative_sales = pd.DataFrame()\n",
    "    outliers_high = pd.DataFrame()\n",
    "    total_outliers = 0\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-1. ë§¤ì¶œ 0ì› ë°ì´í„°\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-1] ë§¤ì¶œ 0ì› ë°ì´í„°\")\n",
    "    print(\"-\" * 40)\n",
    "    zero_sales = df_raw[df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] == 0]\n",
    "    print(f\"ë§¤ì¶œ 0ì› ë°ì´í„°: {len(zero_sales):,}ê±´ ({len(zero_sales)/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "    if len(zero_sales) > 0:\n",
    "        print(\"\\nğŸ“ ë§¤ì¶œ 0ì› - ìƒê¶Œìœ í˜•ë³„ ë¶„í¬:\")\n",
    "        zero_by_type = zero_sales['ìƒê¶Œêµ¬ë¶„_ëª…'].value_counts()\n",
    "        for ìœ í˜•, ê°œìˆ˜ in zero_by_type.items():\n",
    "            print(f\"  - {ìœ í˜•}: {ê°œìˆ˜:,}ê±´\")\n",
    "        \n",
    "        zero_sales[['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ëª…', 'ìƒê¶Œ_ëª…', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']].to_csv(\n",
    "            'eda_í¸ì˜ì _ë§¤ì¶œ0ì›.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: eda_í¸ì˜ì _ë§¤ì¶œ0ì›.csv\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-2. ë§¤ì¶œ ìŒìˆ˜ ë°ì´í„°\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-2] ë§¤ì¶œ ìŒìˆ˜ ë°ì´í„°\")\n",
    "    print(\"-\" * 40)\n",
    "    negative_sales = df_raw[df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] < 0]\n",
    "    print(f\"ë§¤ì¶œ ìŒìˆ˜ ë°ì´í„°: {len(negative_sales):,}ê±´\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-3. ì´ìƒì¹˜ í™•ì¸ (IQR ë°©ì‹)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-3] ì´ìƒì¹˜ í™•ì¸ (ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡ - IQR ë°©ì‹)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    q1 = df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].quantile(0.25)\n",
    "    q3 = df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    \n",
    "    print(f\"\\nğŸ“ IQR ì´ìƒì¹˜ íŒë³„ ê¸°ì¤€:\")\n",
    "    print(f\"  - Q1 (25%): {q1/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"  - Q3 (75%): {q3/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"  - IQR: {iqr/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"  - í•˜í•œ ê²½ê³„: {lower/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    print(f\"  - ìƒí•œ ê²½ê³„: {upper/1e6:,.1f}ë°±ë§Œì›\")\n",
    "    \n",
    "    outliers_low = df_raw[df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] < lower]\n",
    "    outliers_high = df_raw[df_raw['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] > upper]\n",
    "    \n",
    "    print(f\"\\n[í•˜í•œ ì´ìƒì¹˜] {len(outliers_low):,}ê±´\")\n",
    "    print(f\"[ìƒí•œ ì´ìƒì¹˜] {len(outliers_high):,}ê±´ ({len(outliers_high)/len(df_raw)*100:.1f}%)\")\n",
    "    \n",
    "    if len(outliers_high) > 0:\n",
    "        print(\"\\nâš ï¸ ìƒí•œ ì´ìƒì¹˜ TOP 10 (ë§¤ì¶œ ê°€ì¥ ë†’ì€ í¸ì˜ì  ìƒê¶Œ):\")\n",
    "        top10 = outliers_high.nlargest(10, 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡')[['ìƒê¶Œêµ¬ë¶„_ëª…', 'ìƒê¶Œ_ëª…', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']]\n",
    "        for idx, row in top10.iterrows():\n",
    "            print(f\"  - {row['ìƒê¶Œ_ëª…']} ({row['ìƒê¶Œêµ¬ë¶„_ëª…']}, {row['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ']}): {row['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']/1e8:.1f}ì–µì›\")\n",
    "        \n",
    "        # ì´ìƒì¹˜ ë¹ˆë„ TOP 10\n",
    "        print(\"\\nğŸ“ ìƒí•œ ì´ìƒì¹˜ ë¹ˆë„ TOP 10 (ì–´ë–¤ ìƒê¶Œì´ ìì£¼ ì´ìƒì¹˜ë¡œ ì¡íˆë‚˜):\")\n",
    "        freq_high = outliers_high.groupby('ìƒê¶Œ_ëª…').agg(\n",
    "            ì´ìƒì¹˜_íšŸìˆ˜=('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'count'),\n",
    "            í‰ê· _ë§¤ì¶œ=('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'mean')\n",
    "        ).sort_values('ì´ìƒì¹˜_íšŸìˆ˜', ascending=False).head(10)\n",
    "        for ìƒê¶Œ, row in freq_high.iterrows():\n",
    "            print(f\"  - {ìƒê¶Œ}: {row['ì´ìƒì¹˜_íšŸìˆ˜']}ê±´ (í‰ê·  {row['í‰ê· _ë§¤ì¶œ']/1e8:.1f}ì–µì›)\")\n",
    "        \n",
    "        outliers_high_save = outliers_high[['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ëª…', 'ìƒê¶Œ_ëª…', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']].copy()\n",
    "        outliers_high_save['ë§¤ì¶œ_ì–µì›'] = (outliers_high_save['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] / 1e8).round(1)\n",
    "        outliers_high_save = outliers_high_save.sort_values('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', ascending=False)\n",
    "        outliers_high_save.to_csv('eda_í¸ì˜ì _ìƒí•œì´ìƒì¹˜.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… CSV ì €ì¥ ì™„ë£Œ: eda_í¸ì˜ì _ìƒí•œì´ìƒì¹˜.csv ({len(outliers_high)}ê±´)\")\n",
    "    \n",
    "    total_outliers = len(outliers_low) + len(outliers_high)\n",
    "    print(f\"\\nğŸ“Š ì´ìƒì¹˜ ìš”ì•½:\")\n",
    "    print(f\"  - í•˜í•œ ì´ìƒì¹˜: {len(outliers_low):,}ê±´\")\n",
    "    print(f\"  - ìƒí•œ ì´ìƒì¹˜: {len(outliers_high):,}ê±´\")\n",
    "    print(f\"  - ì „ì²´ ì´ìƒì¹˜: {total_outliers:,}ê±´ ({total_outliers/len(df_raw)*100:.1f}%)\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4-4. ë¶„ê¸°ë³„ ë°ì´í„° ê±´ìˆ˜ í™•ì¸\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[4-4] ë¶„ê¸°ë³„ ë°ì´í„° ê±´ìˆ˜ í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    quarter_counts = df_raw.groupby('ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ').size().sort_index()\n",
    "    print(quarter_counts)\n",
    "    \n",
    "    avg_count = quarter_counts.mean()\n",
    "    print(f\"\\në¶„ê¸° í‰ê·  ë°ì´í„° ìˆ˜: {avg_count:,.0f}ê±´\")\n",
    "    \n",
    "    abnormal_quarters = quarter_counts[abs(quarter_counts - avg_count) > avg_count * 0.2]\n",
    "    if len(abnormal_quarters) > 0:\n",
    "        print(\"\\nâš ï¸ í‰ê·  ëŒ€ë¹„ Â±20% ì´ìƒ ì°¨ì´ë‚˜ëŠ” ë¶„ê¸°:\")\n",
    "        for q, cnt in abnormal_quarters.items():\n",
    "            diff_pct = (cnt - avg_count) / avg_count * 100\n",
    "            print(f\"  - {q}: {cnt}ê±´ ({diff_pct:+.1f}%)\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # =========================================================\n",
    "    # EDA ìš”ì•½\n",
    "    # =========================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA ìš”ì•½ - í¸ì˜ì  ë§¤ì¶œ\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ì „ì²´ ë°ì´í„°: {len(df_raw):,}ê±´\")\n",
    "    print(f\"ë¶„ê¸° ìˆ˜: {df_raw['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "    print(f\"ìƒê¶Œ ìˆ˜: {df_raw['ìƒê¶Œ_ì½”ë“œ'].nunique()}ê°œ\")\n",
    "    print(f\"\\nìƒê¶Œìœ í˜•ë³„ í¸ì˜ì  ì´ ë§¤ì¶œ:\")\n",
    "    for ìœ í˜•, ê¸ˆì•¡ in type_total.items():\n",
    "        print(f\"  - {ìœ í˜•}: {ê¸ˆì•¡/1e12:.2f}ì¡°ì›\")\n",
    "    \n",
    "    issues = []\n",
    "    if len(zero_sales) > 0:\n",
    "        issues.append(f\"ë§¤ì¶œ 0ì›: {len(zero_sales):,}ê±´\")\n",
    "    if len(negative_sales) > 0:\n",
    "        issues.append(f\"ë§¤ì¶œ ìŒìˆ˜: {len(negative_sales):,}ê±´\")\n",
    "    if total_outliers > 0:\n",
    "        issues.append(f\"ì´ìƒì¹˜: {total_outliers:,}ê±´\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nâœ… íŠ¹ë³„í•œ ì´ìŠˆ ì—†ìŒ!\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì €ì¥ëœ CSV íŒŒì¼ ëª©ë¡:\")\n",
    "    print(\"  - ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ì›ë³¸.csv (ì „ì²´ ë°ì´í„°)\")\n",
    "    print(\"  - ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ë¶„ê¸°ë³„_ìƒê¶Œìœ í˜•ë³„.csv (ì§‘ê³„ ë°ì´í„°)\")\n",
    "    if len(zero_sales) > 0:\n",
    "        print(\"  - eda_í¸ì˜ì _ë§¤ì¶œ0ì›.csv\")\n",
    "    if len(outliers_high) > 0:\n",
    "        print(\"  - eda_í¸ì˜ì _ìƒí•œì´ìƒì¹˜.csv\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ğŸ“Š EDA ì™„ë£Œ!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ë©”ì¸ ì‹¤í–‰\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ í”„ë¡œê·¸ë¨ ì‹œì‘\")\n",
    "    print(f\"í˜„ì¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"âš ï¸ ë°ì´í„°ê°€ 57ë§Œê±´ì´ë¼ ìˆ˜ì§‘ì— 10~15ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   (í¸ì˜ì ë§Œ í•„í„°ë§í•˜ë©´ ì•½ 1~2ë§Œê±´ ì˜ˆìƒ)\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # 1. ë°ì´í„° ìˆ˜ì§‘\n",
    "    raw_data = fetch_all_data()\n",
    "    \n",
    "    if raw_data:\n",
    "        # 2. í¸ì˜ì  í•„í„°ë§ + ê¸°ê°„ í•„í„°ë§\n",
    "        df_raw = filter_convenience_store(raw_data, QUARTER_CODES)\n",
    "        \n",
    "        if len(df_raw) > 0:\n",
    "            # 3. ì»¬ëŸ¼ëª… í•œê¸€ ë³€í™˜\n",
    "            existing_cols = {k: v for k, v in COLUMN_MAPPING.items() if k in df_raw.columns}\n",
    "            df_raw = df_raw.rename(columns=existing_cols)\n",
    "            \n",
    "            # 4. ìˆ«ìí˜• ë³€í™˜\n",
    "            numeric_cols = [col for col in df_raw.columns if 'ë§¤ì¶œ' in col]\n",
    "            for col in numeric_cols:\n",
    "                df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')\n",
    "            \n",
    "            # 5. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "            keep_cols = ['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ì½”ë“œ', 'ìƒê¶Œêµ¬ë¶„_ëª…', 'ìƒê¶Œ_ì½”ë“œ', 'ìƒê¶Œ_ëª…',\n",
    "                         'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡']\n",
    "            df_raw = df_raw[[col for col in keep_cols if col in df_raw.columns]]\n",
    "            \n",
    "            # 6. ì›ë³¸ ë°ì´í„° ì €ì¥\n",
    "            df_raw.to_csv('ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ì›ë³¸.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… ì €ì¥ ì™„ë£Œ: ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ì›ë³¸.csv ({len(df_raw):,}ê±´)\")\n",
    "            \n",
    "            # 7. ë¶„ê¸°ë³„ + ìƒê¶Œìœ í˜•ë³„ ì§‘ê³„\n",
    "            df_agg = aggregate_by_quarter_type(df_raw)\n",
    "            \n",
    "            # 8. ì§‘ê³„ ë°ì´í„° ì €ì¥\n",
    "            df_agg.to_csv('ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ë¶„ê¸°ë³„_ìƒê¶Œìœ í˜•ë³„.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… ì €ì¥ ì™„ë£Œ: ì„œìš¸ì‹œ_í¸ì˜ì ë§¤ì¶œ_ë¶„ê¸°ë³„_ìƒê¶Œìœ í˜•ë³„.csv ({len(df_agg)}ê±´)\")\n",
    "            \n",
    "            # 9. EDA ì‹¤í–‰\n",
    "            df_agg = run_eda(df_raw, df_agg)\n",
    "            \n",
    "        else:\n",
    "            print(\"í¸ì˜ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "    \n",
    "    print(f\"\\nğŸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

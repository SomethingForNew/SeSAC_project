{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¶„ì„4: ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„\n",
    "\n",
    "## ëª©ì \n",
    "ë‰´ìŠ¤ ê¸ì •/ë¶€ì •ì´ ì§‘ê°’ì— ë¯¸ì¹œ ì˜í–¥ ë¶„ì„\n",
    "\n",
    "## ë¶„ì„ ë‚´ìš©\n",
    "- ê°ì„±ì§€ìˆ˜ vs ì‹¤ê±°ë˜ê°€ ìƒê´€ê´€ê³„\n",
    "- ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ì¦ê°€ ì‹œì  ì „í›„ ë¹„êµ\n",
    "- ì‹œì°¨ ë¶„ì„ (Lag Analysis)\n",
    "- êµ¬ë³„ ë¯¼ê°ë„ ì°¨ì´\n",
    "\n",
    "## í•µì‹¬ ì§ˆë¬¸\n",
    "1. ê¸ì • ë‰´ìŠ¤ê°€ ë§ìœ¼ë©´ ì§‘ê°’ì´ ì˜¤ë¥´ëŠ”ê°€?\n",
    "2. ë°˜ì‘ ì†ë„ëŠ” ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?\n",
    "3. ì–´ëŠ êµ¬ê°€ ë‰´ìŠ¤ì— ê°€ì¥ ë¯¼ê°í•œê°€?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ)\n",
    "!pip install pandas numpy matplotlib seaborn plotly scipy konlpy transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'  # Mac\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "### 2-1. ë‰´ìŠ¤ í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ\n",
    "íŒ€ì›ì´ ìˆ˜ì§‘í•œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œ ìˆ˜ì • í•„ìš”)\n",
    "# news_df = pd.read_csv('../data/news_data.csv')\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´ í•„ìš”)\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
    "\n",
    "# ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„±\n",
    "news_df = pd.DataFrame({\n",
    "    'date': np.random.choice(dates, 1000),\n",
    "    'title': ['ë¶€ë™ì‚° ê´€ë ¨ ë‰´ìŠ¤ ' + str(i) for i in range(1000)],\n",
    "    'content': ['ë‰´ìŠ¤ ë³¸ë¬¸ ë‚´ìš© ' + str(i) for i in range(1000)],\n",
    "    'source': np.random.choice(['ì¤‘ì•™ì¼ë³´', 'ì¡°ì„ ì¼ë³´', 'í•œê²¨ë ˆ', 'MBC', 'SBS'], 1000),\n",
    "    'region': np.random.choice(['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ë§ˆí¬êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬'], 1000)\n",
    "})\n",
    "\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "news_df = news_df.sort_values('date').reset_index(drop=True)\n",
    "print(f\"ë‰´ìŠ¤ ë°ì´í„°: {len(news_df)}ê±´\")\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. ì‹¤ê±°ë˜ê°€ ë°ì´í„° ë¡œë“œ\n",
    "ê³µê³µë°ì´í„° APIì—ì„œ ìˆ˜ì§‘í•œ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ê±°ë˜ê°€ ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œ ìˆ˜ì • í•„ìš”)\n",
    "# price_df = pd.read_csv('../data/estate_price.csv')\n",
    "\n",
    "# ìƒ˜í”Œ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìƒì„±\n",
    "regions = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ë§ˆí¬êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬']\n",
    "months = pd.date_range(start='2023-01-01', end='2024-12-31', freq='M')\n",
    "\n",
    "price_data = []\n",
    "base_prices = {'ê°•ë‚¨êµ¬': 25, 'ì„œì´ˆêµ¬': 22, 'ì†¡íŒŒêµ¬': 18, 'ë§ˆí¬êµ¬': 15, 'ìš©ì‚°êµ¬': 20, 'ì„±ë™êµ¬': 14}\n",
    "\n",
    "for region in regions:\n",
    "    base = base_prices[region]\n",
    "    for i, month in enumerate(months):\n",
    "        # íŠ¸ë Œë“œ + ë…¸ì´ì¦ˆ\n",
    "        price = base + (i * 0.1) + np.random.normal(0, 0.5)\n",
    "        price_data.append({\n",
    "            'date': month,\n",
    "            'region': region,\n",
    "            'avg_price': price  # ì–µì› ë‹¨ìœ„ (í‰ë‹¹)\n",
    "        })\n",
    "\n",
    "price_df = pd.DataFrame(price_data)\n",
    "price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "print(f\"ì‹¤ê±°ë˜ê°€ ë°ì´í„°: {len(price_df)}ê±´\")\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê°ì„± ë¶„ì„ (Sentiment Analysis)\n",
    "\n",
    "### 3-1. ë°©ë²• 1: í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„ (ê°„ë‹¨í•œ ë°©ë²•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶€ë™ì‚° ê´€ë ¨ ê°ì„± í‚¤ì›Œë“œ ì‚¬ì „\n",
    "positive_keywords = [\n",
    "    'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'í™œí™©', 'íšŒë³µ', 'ìƒìŠ¹ì„¸', 'ê°•ì„¸', 'ì¸ê¸°', 'í˜¸í™©',\n",
    "    'íˆ¬ì', 'ìˆ˜ìµ', 'ê°œë°œ', 'ì¬ê±´ì¶•', 'í˜¸ê°€', 'ì‹ ê³ ê°€', 'í”„ë¦¬ë¯¸ì—„', 'ì™„íŒ',\n",
    "    'ì²­ì•½', 'ë‹¹ì²¨', 'ë¶„ì–‘', 'ë§¤ìˆ˜', 'ì…ì£¼', 'êµí†µí˜¸ì¬', 'GTX', 'ê°œí†µ',\n",
    "    'í•™êµ°', 'ì¸í”„ë¼', 'ê³µì›', 'í¸ì˜ì‹œì„¤', 'ì•ˆì •', 'ì „ë§ì¢‹ìŒ'\n",
    "]\n",
    "\n",
    "negative_keywords = [\n",
    "    'í•˜ë½', 'ê¸‰ë½', 'í­ë½', 'ì¹¨ì²´', 'ë¶ˆí™©', 'í•˜ë½ì„¸', 'ì•½ì„¸', 'ìœ„ê¸°',\n",
    "    'ê±°ë˜ì ˆë²½', 'ë¯¸ë¶„ì–‘', 'ë§¤ë¬¼ì¦ê°€', 'ë§¤ë„', 'ì†ì‹¤', 'ì—­ì „ì„¸', 'ê¹¡í†µì „ì„¸',\n",
    "    'ê·œì œ', 'ëŒ€ì¶œ', 'ê¸ˆë¦¬', 'ì„¸ê¸ˆ', 'ì¢…ë¶€ì„¸', 'ì–‘ë„ì„¸', 'ì·¨ë“ì„¸',\n",
    "    'íˆ¬ê¸°', 'ë²„ë¸”', 'ê³¼ì—´', 'ì¡°ì •', 'ê²½ê¸°ì¹¨ì²´', 'ë¶ˆì•ˆ', 'ìš°ë ¤'\n",
    "]\n",
    "\n",
    "def calculate_sentiment_score(text):\n",
    "    \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ 1)\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    \n",
    "    text = str(text)\n",
    "    pos_count = sum(1 for word in positive_keywords if word in text)\n",
    "    neg_count = sum(1 for word in negative_keywords if word in text)\n",
    "    \n",
    "    total = pos_count + neg_count\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    \n",
    "    return (pos_count - neg_count) / total\n",
    "\n",
    "# ê°ì„± ì ìˆ˜ ê³„ì‚°\n",
    "news_df['sentiment_score'] = news_df['title'].apply(calculate_sentiment_score) + \\\n",
    "                              news_df['content'].apply(calculate_sentiment_score) * 0.5\n",
    "\n",
    "# ì •ê·œí™”\n",
    "news_df['sentiment_score'] = news_df['sentiment_score'].clip(-1, 1)\n",
    "\n",
    "# ê°ì„± ë ˆì´ë¸” ì¶”ê°€\n",
    "news_df['sentiment_label'] = news_df['sentiment_score'].apply(\n",
    "    lambda x: 'ê¸ì •' if x > 0.1 else ('ë¶€ì •' if x < -0.1 else 'ì¤‘ë¦½')\n",
    ")\n",
    "\n",
    "print(\"ê°ì„± ë¶„í¬:\")\n",
    "print(news_df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. ë°©ë²• 2: KoBERT ê¸°ë°˜ ê°ì„± ë¶„ì„ (ë”¥ëŸ¬ë‹ ë°©ë²•)\n",
    "ë” ì •í™•í•œ ê°ì„± ë¶„ì„ì„ ì›í•  ê²½ìš° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT ê°ì„± ë¶„ì„ (ì„ íƒì  - GPU ê¶Œì¥)\n",
    "# ì‹¤í–‰ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ\n",
    "\n",
    "USE_BERT = False  # Trueë¡œ ë³€ê²½í•˜ë©´ BERT ì‚¬ìš©\n",
    "\n",
    "if USE_BERT:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    # í•œêµ­ì–´ ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"snunlp/KR-FinBert-SC\",  # ê¸ˆìœµ íŠ¹í™” í•œêµ­ì–´ BERT\n",
    "        tokenizer=\"snunlp/KR-FinBert-SC\"\n",
    "    )\n",
    "    \n",
    "    def bert_sentiment(text):\n",
    "        if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "            return 0\n",
    "        try:\n",
    "            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (512 í† í°)\n",
    "            text = str(text)[:500]\n",
    "            result = sentiment_pipeline(text)[0]\n",
    "            # positive -> 1, negative -> -1\n",
    "            if result['label'] == 'positive':\n",
    "                return result['score']\n",
    "            else:\n",
    "                return -result['score']\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    # ë°°ì¹˜ ì²˜ë¦¬ (ì‹œê°„ ì ˆì•½)\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas()\n",
    "    news_df['bert_sentiment'] = news_df['title'].progress_apply(bert_sentiment)\n",
    "    print(\"BERT ê°ì„± ë¶„ì„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì›”ë³„ ê°ì„±ì§€ìˆ˜ ì§‘ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›”ë³„ ì§‘ê³„\n",
    "news_df['year_month'] = news_df['date'].dt.to_period('M')\n",
    "\n",
    "# ì „ì²´ ì›”ë³„ ê°ì„±ì§€ìˆ˜\n",
    "monthly_sentiment = news_df.groupby('year_month').agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count'],\n",
    "    'sentiment_label': lambda x: (x == 'ê¸ì •').sum() / len(x) * 100  # ê¸ì • ë¹„ìœ¨\n",
    "}).reset_index()\n",
    "\n",
    "monthly_sentiment.columns = ['year_month', 'avg_sentiment', 'sentiment_std', 'news_count', 'positive_ratio']\n",
    "monthly_sentiment['date'] = monthly_sentiment['year_month'].dt.to_timestamp()\n",
    "\n",
    "# êµ¬ë³„ ì›”ë³„ ê°ì„±ì§€ìˆ˜\n",
    "regional_sentiment = news_df.groupby(['year_month', 'region']).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'sentiment_label': lambda x: (x == 'ê¸ì •').sum() / len(x) * 100\n",
    "}).reset_index()\n",
    "\n",
    "regional_sentiment.columns = ['year_month', 'region', 'avg_sentiment', 'positive_ratio']\n",
    "regional_sentiment['date'] = regional_sentiment['year_month'].dt.to_timestamp()\n",
    "\n",
    "print(\"ì›”ë³„ ê°ì„±ì§€ìˆ˜:\")\n",
    "monthly_sentiment.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê°ì„±ì§€ìˆ˜ vs ì‹¤ê±°ë˜ê°€ ìƒê´€ê´€ê³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë³‘í•©\n",
    "price_df['year_month'] = price_df['date'].dt.to_period('M')\n",
    "\n",
    "# ì „ì²´ í‰ê·  ê°€ê²©\n",
    "monthly_price = price_df.groupby('year_month')['avg_price'].mean().reset_index()\n",
    "monthly_price['date'] = monthly_price['year_month'].dt.to_timestamp()\n",
    "\n",
    "# ê°ì„±ì§€ìˆ˜ì™€ ê°€ê²© ë³‘í•©\n",
    "merged_df = pd.merge(\n",
    "    monthly_sentiment[['date', 'avg_sentiment', 'positive_ratio']],\n",
    "    monthly_price[['date', 'avg_price']],\n",
    "    on='date',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "corr_sentiment_price, p_value = pearsonr(\n",
    "    merged_df['avg_sentiment'].dropna(), \n",
    "    merged_df['avg_price'].dropna()\n",
    ")\n",
    "\n",
    "print(f\"ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ìƒê´€ê³„ìˆ˜: {corr_sentiment_price:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"í†µê³„ì  ìœ ì˜ì„±: {'ìœ ì˜í•¨' if p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹œì°¨ ë¶„ì„ (Lag Analysis)\n",
    "\n",
    "ë‰´ìŠ¤ ê°ì„±ì´ ì§‘ê°’ì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸°ê¹Œì§€ ì‹œê°„ì´ ê±¸ë¦¬ëŠ”ì§€ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lag_correlation(df, sentiment_col, price_col, max_lag=6):\n",
    "    \"\"\"ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for lag in range(-max_lag, max_lag + 1):\n",
    "        if lag < 0:\n",
    "            # ê°€ê²©ì´ ê°ì„±ë³´ë‹¤ ë¨¼ì € (ê°€ê²© -> ê°ì„± ì˜í–¥)\n",
    "            sentiment = df[sentiment_col].iloc[-lag:].values\n",
    "            price = df[price_col].iloc[:lag].values\n",
    "        elif lag > 0:\n",
    "            # ê°ì„±ì´ ê°€ê²©ë³´ë‹¤ ë¨¼ì € (ê°ì„± -> ê°€ê²© ì˜í–¥)\n",
    "            sentiment = df[sentiment_col].iloc[:-lag].values\n",
    "            price = df[price_col].iloc[lag:].values\n",
    "        else:\n",
    "            sentiment = df[sentiment_col].values\n",
    "            price = df[price_col].values\n",
    "        \n",
    "        if len(sentiment) > 5 and len(price) > 5:\n",
    "            corr, p_val = pearsonr(sentiment, price)\n",
    "            results.append({\n",
    "                'lag': lag,\n",
    "                'correlation': corr,\n",
    "                'p_value': p_val,\n",
    "                'significant': p_val < 0.05\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ì‹œì°¨ ë¶„ì„ ì‹¤í–‰\n",
    "lag_results = calculate_lag_correlation(merged_df, 'avg_sentiment', 'avg_price', max_lag=6)\n",
    "\n",
    "print(\"ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜:\")\n",
    "print(\"(ì–‘ìˆ˜ lag = ê°ì„±ì´ ê°€ê²©ì— ì„ í–‰, ìŒìˆ˜ lag = ê°€ê²©ì´ ê°ì„±ì— ì„ í–‰)\")\n",
    "print(lag_results.to_string(index=False))\n",
    "\n",
    "# ìµœì  ì‹œì°¨ ì°¾ê¸°\n",
    "best_lag = lag_results.loc[lag_results['correlation'].abs().idxmax()]\n",
    "print(f\"\\nê°€ì¥ ê°•í•œ ìƒê´€ê´€ê³„ ì‹œì°¨: {best_lag['lag']}ê°œì›” (r={best_lag['correlation']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. êµ¬ë³„ ë¯¼ê°ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "regional_correlation = []\n",
    "\n",
    "for region in regions:\n",
    "    # í•´ë‹¹ êµ¬ì˜ ê°ì„±ì§€ìˆ˜\n",
    "    region_sentiment = regional_sentiment[regional_sentiment['region'] == region][['date', 'avg_sentiment']]\n",
    "    \n",
    "    # í•´ë‹¹ êµ¬ì˜ ê°€ê²©\n",
    "    region_price = price_df[price_df['region'] == region][['date', 'avg_price']]\n",
    "    \n",
    "    # ë³‘í•©\n",
    "    region_merged = pd.merge(region_sentiment, region_price, on='date', how='inner')\n",
    "    \n",
    "    if len(region_merged) > 5:\n",
    "        corr, p_val = pearsonr(\n",
    "            region_merged['avg_sentiment'].dropna(),\n",
    "            region_merged['avg_price'].dropna()\n",
    "        )\n",
    "        \n",
    "        regional_correlation.append({\n",
    "            'region': region,\n",
    "            'correlation': corr,\n",
    "            'p_value': p_val,\n",
    "            'sensitivity': abs(corr)  # ì ˆëŒ€ê°’ìœ¼ë¡œ ë¯¼ê°ë„ ì¸¡ì •\n",
    "        })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(regional_correlation)\n",
    "sensitivity_df = sensitivity_df.sort_values('sensitivity', ascending=False)\n",
    "\n",
    "print(\"êµ¬ë³„ ë‰´ìŠ¤ ë¯¼ê°ë„ (ìƒê´€ê³„ìˆ˜ ì ˆëŒ€ê°’ ê¸°ì¤€):\")\n",
    "print(sensitivity_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹œê°í™”\n",
    "\n",
    "### 8-1. ì´ì¤‘ì¶• ì°¨íŠ¸ (ê°ì„±ì§€ìˆ˜ + ì§‘ê°’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly ì´ì¤‘ì¶• ì°¨íŠ¸\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# ê°ì„±ì§€ìˆ˜ (ì™¼ìª½ yì¶•)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged_df['date'],\n",
    "        y=merged_df['avg_sentiment'],\n",
    "        name=\"ê°ì„±ì§€ìˆ˜\",\n",
    "        line=dict(color='blue', width=2),\n",
    "        hovertemplate='ë‚ ì§œ: %{x}<br>ê°ì„±ì§€ìˆ˜: %{y:.3f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "# ì§‘ê°’ (ì˜¤ë¥¸ìª½ yì¶•)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged_df['date'],\n",
    "        y=merged_df['avg_price'],\n",
    "        name=\"í‰ê·  ì§‘ê°’ (ì–µì›/í‰)\",\n",
    "        line=dict(color='red', width=2),\n",
    "        hovertemplate='ë‚ ì§œ: %{x}<br>ì§‘ê°’: %{y:.2f}ì–µ<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': f'ë‰´ìŠ¤ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ì¶”ì´<br><sup>ìƒê´€ê³„ìˆ˜: {corr_sentiment_price:.3f}</sup>',\n",
    "        'x': 0.5\n",
    "    },\n",
    "    xaxis_title=\"ë‚ ì§œ\",\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"ê°ì„±ì§€ìˆ˜\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"ì§‘ê°’ (ì–µì›/í‰)\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›”ë³„ ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ë¹„ìœ¨\n",
    "monthly_sentiment_dist = news_df.groupby(['year_month', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "monthly_sentiment_dist = monthly_sentiment_dist.div(monthly_sentiment_dist.sum(axis=1), axis=0) * 100\n",
    "monthly_sentiment_dist = monthly_sentiment_dist.reset_index()\n",
    "monthly_sentiment_dist['date'] = monthly_sentiment_dist['year_month'].dt.to_timestamp()\n",
    "\n",
    "# Stacked Bar Chart\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {'ê¸ì •': '#2E7D32', 'ì¤‘ë¦½': '#9E9E9E', 'ë¶€ì •': '#C62828'}\n",
    "\n",
    "for sentiment in ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •']:\n",
    "    if sentiment in monthly_sentiment_dist.columns:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=monthly_sentiment_dist['date'],\n",
    "                y=monthly_sentiment_dist[sentiment],\n",
    "                name=sentiment,\n",
    "                marker_color=colors[sentiment],\n",
    "                hovertemplate=f'{sentiment}: %{{y:.1f}}%<extra></extra>'\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ì›”ë³„ ë‰´ìŠ¤ ê°ì„± ë¶„í¬',\n",
    "    xaxis_title='ë‚ ì§œ',\n",
    "    yaxis_title='ë¹„ìœ¨ (%)',\n",
    "    barmode='stack',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-3. ì‹œì°¨ ìƒê´€ë¶„ì„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜ ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "# Bar chart\n",
    "colors = ['#2E7D32' if r > 0 else '#C62828' for r in lag_results['correlation']]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=lag_results['lag'],\n",
    "        y=lag_results['correlation'],\n",
    "        marker_color=colors,\n",
    "        text=[f'{r:.3f}' for r in lag_results['correlation']],\n",
    "        textposition='outside',\n",
    "        hovertemplate='ì‹œì°¨: %{x}ê°œì›”<br>ìƒê´€ê³„ìˆ˜: %{y:.4f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# ìœ ì˜ìˆ˜ì¤€ ì„ \n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", opacity=0.5)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜ (ê°ì„±ì§€ìˆ˜ â†’ ì§‘ê°’)<br><sup>ì–‘ìˆ˜ ì‹œì°¨ = ê°ì„±ì´ ì§‘ê°’ì— ì„ í–‰</sup>',\n",
    "        'x': 0.5\n",
    "    },\n",
    "    xaxis_title='ì‹œì°¨ (ê°œì›”)',\n",
    "    yaxis_title='ìƒê´€ê³„ìˆ˜',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(tickmode='linear', tick0=-6, dtick=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-4. êµ¬ë³„ ë¯¼ê°ë„ íˆíŠ¸ë§µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë³„ ë¯¼ê°ë„ Bar Chart\n",
    "fig = px.bar(\n",
    "    sensitivity_df,\n",
    "    x='region',\n",
    "    y='sensitivity',\n",
    "    color='correlation',\n",
    "    color_continuous_scale='RdYlGn',\n",
    "    title='êµ¬ë³„ ë‰´ìŠ¤ ë¯¼ê°ë„ (ìƒê´€ê³„ìˆ˜ ì ˆëŒ€ê°’)',\n",
    "    labels={'sensitivity': 'ë¯¼ê°ë„', 'region': 'ì§€ì—­êµ¬', 'correlation': 'ìƒê´€ê³„ìˆ˜'},\n",
    "    text=[f'{s:.3f}' for s in sensitivity_df['sensitivity']]\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    xaxis={'categoryorder': 'total descending'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-5. êµ¬ë³„ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ì‚°ì ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë³„ ì‚°ì ë„ (Facet)\n",
    "regional_merged = pd.merge(\n",
    "    regional_sentiment[['date', 'region', 'avg_sentiment']],\n",
    "    price_df[['date', 'region', 'avg_price']],\n",
    "    on=['date', 'region'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    regional_merged,\n",
    "    x='avg_sentiment',\n",
    "    y='avg_price',\n",
    "    color='region',\n",
    "    facet_col='region',\n",
    "    facet_col_wrap=3,\n",
    "    trendline='ols',\n",
    "    title='êµ¬ë³„ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ê´€ê³„',\n",
    "    labels={'avg_sentiment': 'ê°ì„±ì§€ìˆ˜', 'avg_price': 'ì§‘ê°’ (ì–µì›/í‰)', 'region': 'ì§€ì—­êµ¬'}\n",
    ")\n",
    "\n",
    "fig.update_layout(template='plotly_white', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë¶„ì„ ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1ï¸âƒ£ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ìƒê´€ê´€ê³„\")\n",
    "print(f\"   - ìƒê´€ê³„ìˆ˜: {corr_sentiment_price:.4f}\")\n",
    "print(f\"   - P-value: {p_value:.4f}\")\n",
    "if corr_sentiment_price > 0.3:\n",
    "    print(f\"   â†’ ê¸ì •ì  ìƒê´€ê´€ê³„: ê¸ì • ë‰´ìŠ¤ê°€ ë§ì„ìˆ˜ë¡ ì§‘ê°’ ìƒìŠ¹ ê²½í–¥\")\n",
    "elif corr_sentiment_price < -0.3:\n",
    "    print(f\"   â†’ ë¶€ì •ì  ìƒê´€ê´€ê³„: ê¸ì • ë‰´ìŠ¤ê°€ ë§ì„ìˆ˜ë¡ ì§‘ê°’ í•˜ë½ ê²½í–¥\")\n",
    "else:\n",
    "    print(f\"   â†’ ì•½í•œ ìƒê´€ê´€ê³„: ë‰´ìŠ¤ ê°ì„±ê³¼ ì§‘ê°’ì˜ ì§ì ‘ì  ê´€ê³„ ë¯¸ì•½\")\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ ì‹œì°¨ ë¶„ì„ (ë°˜ì‘ ì†ë„)\")\n",
    "print(f\"   - ìµœì  ì‹œì°¨: {int(best_lag['lag'])}ê°œì›”\")\n",
    "print(f\"   - í•´ë‹¹ ì‹œì°¨ ìƒê´€ê³„ìˆ˜: {best_lag['correlation']:.4f}\")\n",
    "if best_lag['lag'] > 0:\n",
    "    print(f\"   â†’ ë‰´ìŠ¤ ê°ì„±ì´ {int(best_lag['lag'])}ê°œì›” í›„ ì§‘ê°’ì— ë°˜ì˜ë˜ëŠ” ê²½í–¥\")\n",
    "elif best_lag['lag'] < 0:\n",
    "    print(f\"   â†’ ì§‘ê°’ ë³€ë™ì´ {int(abs(best_lag['lag']))}ê°œì›” í›„ ë‰´ìŠ¤ ê°ì„±ì— ì˜í–¥\")\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ êµ¬ë³„ ë¯¼ê°ë„ ìˆœìœ„\")\n",
    "for i, row in sensitivity_df.head(3).iterrows():\n",
    "    print(f\"   {sensitivity_df.index.get_loc(i)+1}ìœ„: {row['region']} (ë¯¼ê°ë„: {row['sensitivity']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ (í†µí•©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µí•© ëŒ€ì‹œë³´ë“œ\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ì¶”ì´',\n",
    "        'ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜',\n",
    "        'ì›”ë³„ ê°ì„± ë¶„í¬',\n",
    "        'êµ¬ë³„ ë¯¼ê°ë„'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"secondary_y\": True}, {}],\n",
    "        [{}, {}]\n",
    "    ],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# 1. ì´ì¤‘ì¶• ì°¨íŠ¸ (ê°ì„±ì§€ìˆ˜ + ì§‘ê°’)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=merged_df['date'], y=merged_df['avg_sentiment'], name='ê°ì„±ì§€ìˆ˜', line=dict(color='blue')),\n",
    "    row=1, col=1, secondary_y=False\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=merged_df['date'], y=merged_df['avg_price'], name='ì§‘ê°’', line=dict(color='red')),\n",
    "    row=1, col=1, secondary_y=True\n",
    ")\n",
    "\n",
    "# 2. ì‹œì°¨ ìƒê´€ê³„ìˆ˜\n",
    "lag_colors = ['#2E7D32' if r > 0 else '#C62828' for r in lag_results['correlation']]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=lag_results['lag'], y=lag_results['correlation'], name='ìƒê´€ê³„ìˆ˜', marker_color=lag_colors, showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. ì›”ë³„ ê°ì„± ë¶„í¬\n",
    "for sentiment in ['ê¸ì •', 'ë¶€ì •']:\n",
    "    if sentiment in monthly_sentiment_dist.columns:\n",
    "        color = '#2E7D32' if sentiment == 'ê¸ì •' else '#C62828'\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=monthly_sentiment_dist['date'],\n",
    "                y=monthly_sentiment_dist[sentiment],\n",
    "                name=sentiment,\n",
    "                fill='tozeroy',\n",
    "                line=dict(color=color)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "# 4. êµ¬ë³„ ë¯¼ê°ë„\n",
    "sensitivity_colors = ['#2E7D32' if c > 0 else '#C62828' for c in sensitivity_df['correlation']]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=sensitivity_df['region'], y=sensitivity_df['sensitivity'], name='ë¯¼ê°ë„', marker_color=sensitivity_colors, showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    "    title_text='ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    legend=dict(x=1.05, y=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ ê²°ê³¼ CSV ì €ì¥\n",
    "output_path = '../data/analysis_results/'\n",
    "import os\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# ì›”ë³„ ê°ì„±ì§€ìˆ˜ ì €ì¥\n",
    "monthly_sentiment.to_csv(f'{output_path}monthly_sentiment.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# êµ¬ë³„ ë¯¼ê°ë„ ì €ì¥\n",
    "sensitivity_df.to_csv(f'{output_path}regional_sensitivity.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì‹œì°¨ ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "lag_results.to_csv(f'{output_path}lag_analysis.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ë‰´ìŠ¤ ê°ì„± ê²°ê³¼ ì €ì¥\n",
    "news_df.to_csv(f'{output_path}news_with_sentiment.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"   ì €ì¥ ìœ„ì¹˜: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

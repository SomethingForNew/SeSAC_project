{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¶„ì„4: ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„\n",
    "\n",
    "## ëª©ì \n",
    "ë‰´ìŠ¤ ê¸ì •/ë¶€ì •ì´ ì§‘ê°’ì— ë¯¸ì¹œ ì˜í–¥ ë¶„ì„\n",
    "\n",
    "## ë¶„ì„ ëŒ€ìƒ\n",
    "- **ì§€ì—­**: ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬ (ê°•ë‚¨3êµ¬)\n",
    "- **ê¸°ê°„**: 2023ë…„ ~ 2025ë…„ (3ë…„)\n",
    "- **ë‰´ìŠ¤ ì¶œì²˜**: ì¤‘ì•™ì¼ë³´ ë¶€ë™ì‚° ë‰´ìŠ¤\n",
    "- **ê°€ê²© ì¶œì²˜**: ì„œìš¸ ì—´ë¦°ë°ì´í„° ê´‘ì¥ API\n",
    "\n",
    "## ë¶„ì„ ë‚´ìš©\n",
    "- ê°ì„±ì§€ìˆ˜ vs ì‹¤ê±°ë˜ê°€ ìƒê´€ê´€ê³„\n",
    "- ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ì¦ê°€ ì‹œì  ì „í›„ ë¹„êµ\n",
    "- ì‹œì°¨ ë¶„ì„ (Lag Analysis)\n",
    "- êµ¬ë³„ ë¯¼ê°ë„ ì°¨ì´\n",
    "\n",
    "## í•µì‹¬ ì§ˆë¬¸\n",
    "1. ê¸ì • ë‰´ìŠ¤ê°€ ë§ìœ¼ë©´ ì§‘ê°’ì´ ì˜¤ë¥´ëŠ”ê°€?\n",
    "2. ë°˜ì‘ ì†ë„ëŠ” ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?\n",
    "3. ì–´ëŠ êµ¬ê°€ ë‰´ìŠ¤ì— ê°€ì¥ ë¯¼ê°í•œê°€?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ)\n",
    "# !pip install pandas numpy matplotlib seaborn plotly scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, linregress\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'  # Mac\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "### 2-1. ë‰´ìŠ¤ í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ (ì¤‘ì•™ì¼ë³´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ì‹¤ì œ ë°ì´í„° ë¡œë“œ (íŒ€ì› í¬ë¡¤ë§ ë°ì´í„°)\n",
    "# ============================================\n",
    "# news_df = pd.read_csv('../data/news_data.csv')\n",
    "\n",
    "# ============================================\n",
    "# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš© - ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´ í•„ìš”)\n",
    "# ============================================\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3ë…„ì¹˜ ë°ì´í„°: 2023-01-01 ~ 2025-12-31\n",
    "dates = pd.date_range(start='2023-01-01', end='2025-12-31', freq='D')\n",
    "\n",
    "# ê°•ë‚¨3êµ¬ + ì¤‘ì•™ì¼ë³´\n",
    "REGIONS = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬']\n",
    "SOURCE = 'ì¤‘ì•™ì¼ë³´'\n",
    "\n",
    "# ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„± (ê°ì„± í‚¤ì›Œë“œ í¬í•¨)\n",
    "sample_titles = [\n",
    "    'ê°•ë‚¨ ì•„íŒŒíŠ¸ ê°€ê²© ê¸‰ë“±, ì‹ ê³ ê°€ ê²½ì‹ ',\n",
    "    'ì„œì´ˆêµ¬ ì¬ê±´ì¶• í˜¸ì¬ë¡œ ë§¤ìˆ˜ì„¸ ì¦ê°€',\n",
    "    'ì†¡íŒŒêµ¬ ì§‘ê°’ í•˜ë½ì„¸, ê±°ë˜ì ˆë²½ ì§€ì†',\n",
    "    'ê¸ˆë¦¬ì¸ìƒ ì—¬íŒŒë¡œ ë¶€ë™ì‚° ì‹œì¥ ì¹¨ì²´',\n",
    "    'ê°•ë‚¨3êµ¬ ì²­ì•½ ì—´ê¸° ëœ¨ê±°ì›Œ',\n",
    "    'GTX ê°œí†µ ê¸°ëŒ€ê°ì— ì§‘ê°’ ìƒìŠ¹',\n",
    "    'ì¢…ë¶€ì„¸ ë¶€ë‹´ìœ¼ë¡œ ë§¤ë¬¼ ì¦ê°€',\n",
    "    'ë¶€ë™ì‚° ê·œì œ ì™„í™” ê¸°ëŒ€ê° í™•ì‚°',\n",
    "    'ê°•ë‚¨ ì¬ê±´ì¶• ë¶„ì–‘ê°€ ì‹ ê³ ê°€ ê¸°ë¡',\n",
    "    'ì „ì„¸ ì‹œì¥ ë¶ˆì•ˆ, ì—­ì „ì„¸ ìš°ë ¤',\n",
    "    'ì„œì´ˆêµ¬ í•™êµ° ì¸ê¸°ë¡œ ë§¤ìˆ˜ ë¬¸ì˜ ì¦ê°€',\n",
    "    'ì†¡íŒŒêµ¬ ì‹ ì¶• ì•„íŒŒíŠ¸ ì™„íŒ í–‰ì§„',\n",
    "    'ë¶€ë™ì‚° ê²½ê¸°ì¹¨ì²´ ì¥ê¸°í™” ì „ë§',\n",
    "    'ê°•ë‚¨ í”„ë¦¬ë¯¸ì—„ ì•„íŒŒíŠ¸ íˆ¬ì ìˆ˜ìµ ì¦ê°€',\n",
    "    'ëŒ€ì¶œ ê·œì œë¡œ ë§¤ìˆ˜ì„¸ ìœ„ì¶•'\n",
    "]\n",
    "\n",
    "n_news = 1500\n",
    "news_df = pd.DataFrame({\n",
    "    'date': np.random.choice(dates, n_news),\n",
    "    'title': np.random.choice(sample_titles, n_news),\n",
    "    'content': np.random.choice(sample_titles, n_news),\n",
    "    'source': [SOURCE] * n_news,\n",
    "    'region': np.random.choice(REGIONS, n_news)\n",
    "})\n",
    "\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "news_df = news_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"ë‰´ìŠ¤ ë°ì´í„°: {len(news_df):,}ê±´\")\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. ë‰´ìŠ¤ ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ë‰´ìŠ¤ ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ê¸°ë³¸ ì •ë³´\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nì „ì²´ ë‰´ìŠ¤: {len(news_df):,}ê±´\")\n",
    "print(f\"ê¸°ê°„: {news_df['date'].min().strftime('%Y-%m-%d')} ~ {news_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# ì›”ë³„ í‰ê·  ë‰´ìŠ¤ ê±´ìˆ˜\n",
    "months_count = news_df['date'].dt.to_period('M').nunique()\n",
    "print(f\"ë¶„ì„ ê¸°ê°„: {months_count}ê°œì›”\")\n",
    "print(f\"ì›”í‰ê·  ë‰´ìŠ¤: {len(news_df)/months_count:.0f}ê±´\")\n",
    "\n",
    "# êµ¬ë³„ ë‰´ìŠ¤ ê±´ìˆ˜\n",
    "print(f\"\\n[êµ¬ë³„ ë‰´ìŠ¤ ê±´ìˆ˜]\")\n",
    "print(news_df['region'].value_counts())\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(f\"\\n[ê²°ì¸¡ì¹˜ í™•ì¸]\")\n",
    "print(news_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. ì‹¤ê±°ë˜ê°€ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ì‹¤ì œ ë°ì´í„° ë¡œë“œ (íŒ€ì› API ë°ì´í„°)\n",
    "# ============================================\n",
    "# price_df = pd.read_csv('../data/estate_price.csv')\n",
    "\n",
    "# ============================================\n",
    "# ìƒ˜í”Œ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
    "# ============================================\n",
    "\n",
    "# 3ë…„ì¹˜ ì›”ë³„ ë°ì´í„°\n",
    "months = pd.date_range(start='2023-01-01', end='2025-12-31', freq='M')\n",
    "\n",
    "# ê°•ë‚¨3êµ¬ í‰ê·  ì‹œì„¸ (ì–µì› ê¸°ì¤€)\n",
    "base_prices = {\n",
    "    'ê°•ë‚¨êµ¬': 25,\n",
    "    'ì„œì´ˆêµ¬': 22,\n",
    "    'ì†¡íŒŒêµ¬': 18\n",
    "}\n",
    "\n",
    "price_data = []\n",
    "for region in REGIONS:\n",
    "    base = base_prices[region]\n",
    "    for i, month in enumerate(months):\n",
    "        price = base + (i * 0.08) + np.random.normal(0, 0.3)\n",
    "        price_data.append({\n",
    "            'date': month,\n",
    "            'region': region,\n",
    "            'avg_price': round(price, 2)\n",
    "        })\n",
    "\n",
    "price_df = pd.DataFrame(price_data)\n",
    "price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "\n",
    "print(f\"ì‹¤ê±°ë˜ê°€ ë°ì´í„°: {len(price_df):,}ê±´\")\n",
    "print(f\"ê¸°ê°„: {price_df['date'].min().strftime('%Y-%m')} ~ {price_df['date'].max().strftime('%Y-%m')}\")\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê°ì„± ë¶„ì„ (Sentiment Analysis)\n",
    "\n",
    "### 3-1. í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶€ë™ì‚° ê´€ë ¨ ê°ì„± í‚¤ì›Œë“œ ì‚¬ì „\n",
    "positive_keywords = [\n",
    "    'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'í™œí™©', 'íšŒë³µ', 'ìƒìŠ¹ì„¸', 'ê°•ì„¸', 'ì¸ê¸°', 'í˜¸í™©',\n",
    "    'íˆ¬ì', 'ìˆ˜ìµ', 'ê°œë°œ', 'ì¬ê±´ì¶•', 'í˜¸ê°€', 'ì‹ ê³ ê°€', 'í”„ë¦¬ë¯¸ì—„', 'ì™„íŒ',\n",
    "    'ì²­ì•½', 'ë‹¹ì²¨', 'ë¶„ì–‘', 'ë§¤ìˆ˜', 'ì…ì£¼', 'êµí†µí˜¸ì¬', 'GTX', 'ê°œí†µ',\n",
    "    'í•™êµ°', 'ì¸í”„ë¼', 'ê³µì›', 'í¸ì˜ì‹œì„¤', 'ì•ˆì •', 'ì „ë§ì¢‹ìŒ'\n",
    "]\n",
    "\n",
    "negative_keywords = [\n",
    "    'í•˜ë½', 'ê¸‰ë½', 'í­ë½', 'ì¹¨ì²´', 'ë¶ˆí™©', 'í•˜ë½ì„¸', 'ì•½ì„¸', 'ìœ„ê¸°',\n",
    "    'ê±°ë˜ì ˆë²½', 'ë¯¸ë¶„ì–‘', 'ë§¤ë¬¼ì¦ê°€', 'ë§¤ë„', 'ì†ì‹¤', 'ì—­ì „ì„¸', 'ê¹¡í†µì „ì„¸',\n",
    "    'ê·œì œ', 'ëŒ€ì¶œ', 'ê¸ˆë¦¬', 'ì„¸ê¸ˆ', 'ì¢…ë¶€ì„¸', 'ì–‘ë„ì„¸', 'ì·¨ë“ì„¸',\n",
    "    'íˆ¬ê¸°', 'ë²„ë¸”', 'ê³¼ì—´', 'ì¡°ì •', 'ê²½ê¸°ì¹¨ì²´', 'ë¶ˆì•ˆ', 'ìš°ë ¤'\n",
    "]\n",
    "\n",
    "def calculate_sentiment_score(text):\n",
    "    \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ 1)\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    \n",
    "    text = str(text)\n",
    "    pos_count = sum(1 for word in positive_keywords if word in text)\n",
    "    neg_count = sum(1 for word in negative_keywords if word in text)\n",
    "    \n",
    "    total = pos_count + neg_count\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    \n",
    "    return (pos_count - neg_count) / total\n",
    "\n",
    "# ê°ì„± ì ìˆ˜ ê³„ì‚° (ì œëª© + ë³¸ë¬¸)\n",
    "news_df['sentiment_score'] = (\n",
    "    news_df['title'].apply(calculate_sentiment_score) * 0.6 +\n",
    "    news_df['content'].apply(calculate_sentiment_score) * 0.4\n",
    ")\n",
    "\n",
    "# ì •ê·œí™”\n",
    "news_df['sentiment_score'] = news_df['sentiment_score'].clip(-1, 1)\n",
    "\n",
    "# ê°ì„± ë ˆì´ë¸” ì¶”ê°€\n",
    "news_df['sentiment_label'] = news_df['sentiment_score'].apply(\n",
    "    lambda x: 'ê¸ì •' if x > 0.1 else ('ë¶€ì •' if x < -0.1 else 'ì¤‘ë¦½')\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š ê°ì„± ë¶„í¬:\")\n",
    "print(news_df['sentiment_label'].value_counts())\n",
    "print(f\"\\ní‰ê·  ê°ì„± ì ìˆ˜: {news_df['sentiment_score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. ê°ì„± í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ê°ì„± í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„\n",
    "# ============================================\n",
    "\n",
    "# ê¸ì • í‚¤ì›Œë“œ ë¹ˆë„\n",
    "pos_counts = {}\n",
    "for keyword in positive_keywords:\n",
    "    count = news_df['title'].str.contains(keyword, na=False).sum()\n",
    "    count += news_df['content'].str.contains(keyword, na=False).sum()\n",
    "    if count > 0:\n",
    "        pos_counts[keyword] = count\n",
    "\n",
    "# ë¶€ì • í‚¤ì›Œë“œ ë¹ˆë„\n",
    "neg_counts = {}\n",
    "for keyword in negative_keywords:\n",
    "    count = news_df['title'].str.contains(keyword, na=False).sum()\n",
    "    count += news_df['content'].str.contains(keyword, na=False).sum()\n",
    "    if count > 0:\n",
    "        neg_counts[keyword] = count\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë³€í™˜\n",
    "pos_df = pd.DataFrame(pos_counts.items(), columns=['keyword', 'count'])\n",
    "pos_df = pos_df.sort_values('count', ascending=False).head(10)\n",
    "\n",
    "neg_df = pd.DataFrame(neg_counts.items(), columns=['keyword', 'count'])\n",
    "neg_df = neg_df.sort_values('count', ascending=False).head(10)\n",
    "\n",
    "# ê¸ì • vs ë¶€ì • ì´í•© ë¹„êµ\n",
    "total_pos = sum(pos_counts.values()) if pos_counts else 0\n",
    "total_neg = sum(neg_counts.values()) if neg_counts else 0\n",
    "\n",
    "print(f\"ê¸ì • í‚¤ì›Œë“œ ì´ ë“±ì¥: {total_pos:,}íšŒ\")\n",
    "print(f\"ë¶€ì • í‚¤ì›Œë“œ ì´ ë“±ì¥: {total_neg:,}íšŒ\")\n",
    "print(f\"ê¸ì •/ë¶€ì • ë¹„ìœ¨: {total_pos/(total_neg+1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™” - ê¸ì • í‚¤ì›Œë“œ TOP 10\n",
    "if len(pos_df) > 0:\n",
    "    fig_pos = px.bar(\n",
    "        pos_df,\n",
    "        x='keyword',\n",
    "        y='count',\n",
    "        title='ğŸ“ˆ ê¸ì • í‚¤ì›Œë“œ TOP 10',\n",
    "        color_discrete_sequence=['#4CAF50'],\n",
    "        text='count'\n",
    "    )\n",
    "    fig_pos.update_traces(textposition='outside')\n",
    "    fig_pos.update_layout(template='plotly_white', height=400)\n",
    "    fig_pos.show()\n",
    "\n",
    "# ì‹œê°í™” - ë¶€ì • í‚¤ì›Œë“œ TOP 10\n",
    "if len(neg_df) > 0:\n",
    "    fig_neg = px.bar(\n",
    "        neg_df,\n",
    "        x='keyword',\n",
    "        y='count',\n",
    "        title='ğŸ“‰ ë¶€ì • í‚¤ì›Œë“œ TOP 10',\n",
    "        color_discrete_sequence=['#F44336'],\n",
    "        text='count'\n",
    "    )\n",
    "    fig_neg.update_traces(textposition='outside')\n",
    "    fig_neg.update_layout(template='plotly_white', height=400)\n",
    "    fig_neg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì›”ë³„ ê°ì„±ì§€ìˆ˜ ì§‘ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›”ë³„ ì§‘ê³„\n",
    "news_df['year_month'] = news_df['date'].dt.to_period('M')\n",
    "\n",
    "# ì „ì²´ ì›”ë³„ ê°ì„±ì§€ìˆ˜\n",
    "monthly_sentiment = news_df.groupby('year_month').agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count'],\n",
    "    'sentiment_label': lambda x: (x == 'ê¸ì •').sum() / len(x) * 100\n",
    "}).reset_index()\n",
    "\n",
    "monthly_sentiment.columns = ['year_month', 'avg_sentiment', 'sentiment_std', 'news_count', 'positive_ratio']\n",
    "monthly_sentiment['date'] = monthly_sentiment['year_month'].dt.to_timestamp()\n",
    "\n",
    "# êµ¬ë³„ ì›”ë³„ ê°ì„±ì§€ìˆ˜\n",
    "regional_sentiment = news_df.groupby(['year_month', 'region']).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'sentiment_label': lambda x: (x == 'ê¸ì •').sum() / len(x) * 100\n",
    "}).reset_index()\n",
    "\n",
    "regional_sentiment.columns = ['year_month', 'region', 'avg_sentiment', 'positive_ratio']\n",
    "regional_sentiment['date'] = regional_sentiment['year_month'].dt.to_timestamp()\n",
    "\n",
    "print(\"ğŸ“… ì›”ë³„ ê°ì„±ì§€ìˆ˜:\")\n",
    "monthly_sentiment.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê°ì„±ì§€ìˆ˜ vs ì‹¤ê±°ë˜ê°€ ìƒê´€ê´€ê³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë³‘í•©\n",
    "price_df['year_month'] = price_df['date'].dt.to_period('M')\n",
    "price_df['date'] = price_df['year_month'].dt.to_timestamp()\n",
    "\n",
    "# ì „ì²´ í‰ê·  ê°€ê²© (ê°•ë‚¨3êµ¬ í‰ê· )\n",
    "monthly_price = price_df.groupby('year_month')['avg_price'].mean().reset_index()\n",
    "monthly_price['date'] = monthly_price['year_month'].dt.to_timestamp()\n",
    "\n",
    "# ê°ì„±ì§€ìˆ˜ì™€ ê°€ê²© ë³‘í•©\n",
    "merged_df = pd.merge(\n",
    "    monthly_sentiment[['date', 'avg_sentiment', 'positive_ratio', 'news_count']],\n",
    "    monthly_price[['date', 'avg_price']],\n",
    "    on='date',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "if not merged_df.empty and len(merged_df) > 5:\n",
    "    corr_sentiment_price, p_value = pearsonr(\n",
    "        merged_df['avg_sentiment'].dropna(), \n",
    "        merged_df['avg_price'].dropna()\n",
    "    )\n",
    "else:\n",
    "    corr_sentiment_price, p_value = 0, 1.0\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ“Š ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ìƒê´€ê´€ê³„ ë¶„ì„\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ìƒê´€ê³„ìˆ˜ (Pearson r): {corr_sentiment_price:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"í†µê³„ì  ìœ ì˜ì„±: {'âœ… ìœ ì˜í•¨ (p < 0.05)' if p_value < 0.05 else 'âŒ ìœ ì˜í•˜ì§€ ì•ŠìŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹œì°¨ ë¶„ì„ (Lag Analysis)\n",
    "\n",
    "ë‰´ìŠ¤ ê°ì„±ì´ ì§‘ê°’ì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸°ê¹Œì§€ ì‹œê°„ì´ ê±¸ë¦¬ëŠ”ì§€ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lag_correlation(df, sentiment_col, price_col, max_lag=6):\n",
    "    \"\"\"ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for lag in range(-max_lag, max_lag + 1):\n",
    "        if lag < 0:\n",
    "            sentiment = df[sentiment_col].iloc[-lag:].values\n",
    "            price = df[price_col].iloc[:lag].values\n",
    "        elif lag > 0:\n",
    "            sentiment = df[sentiment_col].iloc[:-lag].values\n",
    "            price = df[price_col].iloc[lag:].values\n",
    "        else:\n",
    "            sentiment = df[sentiment_col].values\n",
    "            price = df[price_col].values\n",
    "        \n",
    "        if len(sentiment) > 5 and len(price) > 5:\n",
    "            corr, p_val = pearsonr(sentiment, price)\n",
    "            results.append({\n",
    "                'lag': lag,\n",
    "                'correlation': corr,\n",
    "                'p_value': p_val,\n",
    "                'significant': 'âœ…' if p_val < 0.05 else ''\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ì‹œì°¨ ë¶„ì„ ì‹¤í–‰\n",
    "lag_results = calculate_lag_correlation(merged_df, 'avg_sentiment', 'avg_price', max_lag=6)\n",
    "\n",
    "print(\"ğŸ“Š ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜:\")\n",
    "print(\"(ì–‘ìˆ˜ lag = ê°ì„±ì´ ê°€ê²©ì— ì„ í–‰, ìŒìˆ˜ lag = ê°€ê²©ì´ ê°ì„±ì— ì„ í–‰)\")\n",
    "print(lag_results.to_string(index=False))\n",
    "\n",
    "# ìµœì  ì‹œì°¨ ì°¾ê¸°\n",
    "if not lag_results.empty and lag_results['correlation'].notna().any():\n",
    "    best_lag = lag_results.loc[lag_results['correlation'].abs().idxmax()]\n",
    "    print(f\"\\nğŸ¯ ê°€ì¥ ê°•í•œ ìƒê´€ê´€ê³„: {int(best_lag['lag'])}ê°œì›” ì‹œì°¨ (r={best_lag['correlation']:.4f})\")\n",
    "else:\n",
    "    best_lag = pd.Series({'lag': 0, 'correlation': 0})\n",
    "    print(\"\\nìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ì¦ê°€ ì‹œì  ì „í›„ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ê°ì„± ê¸‰ë³€ ì‹œì  ë¶„ì„ (ì „í›„ ë¹„êµ)\n",
    "# ============================================\n",
    "\n",
    "# ì „ì›” ëŒ€ë¹„ ê°ì„± ë³€í™”ëŸ‰ ê³„ì‚°\n",
    "monthly_sentiment_sorted = monthly_sentiment.sort_values('date').copy()\n",
    "monthly_sentiment_sorted['sentiment_change'] = monthly_sentiment_sorted['avg_sentiment'].diff()\n",
    "\n",
    "# ê°ì„± ê¸‰ë“± ì‹œì  (ìƒìœ„ 3ê°œì›”)\n",
    "sentiment_spikes = monthly_sentiment_sorted.nlargest(3, 'sentiment_change')\n",
    "\n",
    "# ê°ì„± ê¸‰ë½ ì‹œì  (í•˜ìœ„ 3ê°œì›”)\n",
    "sentiment_drops = monthly_sentiment_sorted.nsmallest(3, 'sentiment_change')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ê°ì„± ê¸‰ë³€ ì‹œì  ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ”º ê°ì„± ê¸‰ë“± TOP 3:\")\n",
    "for idx, row in sentiment_spikes.iterrows():\n",
    "    print(f\"   {row['date'].strftime('%Y-%m')}: ë³€í™”ëŸ‰ {row['sentiment_change']:+.3f}\")\n",
    "\n",
    "print(\"\\nğŸ”» ê°ì„± ê¸‰ë½ TOP 3:\")\n",
    "for idx, row in sentiment_drops.iterrows():\n",
    "    if pd.notna(row['sentiment_change']):\n",
    "        print(f\"   {row['date'].strftime('%Y-%m')}: ë³€í™”ëŸ‰ {row['sentiment_change']:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì„± ê¸‰ë“± ì‹œì ì˜ ì§‘ê°’ ë³€í™” ë¶„ì„\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ˆ ê°ì„± ê¸‰ë“± ì‹œì  ì „í›„ ì§‘ê°’ ë³€í™”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for idx, row in sentiment_spikes.iterrows():\n",
    "    event_date = row['date']\n",
    "    print(f\"\\nâ–¶ {event_date.strftime('%Y-%m')} (ê°ì„± ë³€í™”: {row['sentiment_change']:+.3f})\")\n",
    "    \n",
    "    # í•´ë‹¹ ì‹œì  ì „í›„ ë°ì´í„°\n",
    "    event_data = merged_df[\n",
    "        (merged_df['date'] >= event_date - pd.DateOffset(months=2)) &\n",
    "        (merged_df['date'] <= event_date + pd.DateOffset(months=2))\n",
    "    ].copy()\n",
    "    \n",
    "    if len(event_data) > 0:\n",
    "        before = event_data[event_data['date'] < event_date]['avg_price'].mean()\n",
    "        after = event_data[event_data['date'] > event_date]['avg_price'].mean()\n",
    "        current = event_data[event_data['date'] == event_date]['avg_price'].values\n",
    "        \n",
    "        if len(current) > 0 and pd.notna(before) and pd.notna(after):\n",
    "            current = current[0]\n",
    "            print(f\"   ì´ì „ 2ê°œì›” í‰ê· : {before:.2f}ì–µ\")\n",
    "            print(f\"   ë‹¹ì›”: {current:.2f}ì–µ\")\n",
    "            print(f\"   ì´í›„ 2ê°œì›” í‰ê· : {after:.2f}ì–µ\")\n",
    "            print(f\"   ë³€í™”: {after - before:+.2f}ì–µ ({(after-before)/before*100:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™” - ê°ì„± ë³€í™”ëŸ‰ + ì§‘ê°’ ë³€í™”ìœ¨ ë¹„êµ\n",
    "merged_sorted = merged_df.sort_values('date').copy()\n",
    "merged_sorted['price_change'] = merged_sorted['avg_price'].pct_change() * 100\n",
    "merged_sorted['sentiment_change'] = merged_sorted['avg_sentiment'].diff()\n",
    "\n",
    "fig_change = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# ê°ì„± ë³€í™”ëŸ‰ (ë§‰ëŒ€)\n",
    "colors = ['#4CAF50' if x > 0 else '#F44336' for x in merged_sorted['sentiment_change'].fillna(0)]\n",
    "fig_change.add_trace(\n",
    "    go.Bar(\n",
    "        x=merged_sorted['date'],\n",
    "        y=merged_sorted['sentiment_change'],\n",
    "        name='ê°ì„± ë³€í™”ëŸ‰',\n",
    "        marker_color=colors,\n",
    "        opacity=0.7\n",
    "    ),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "# ì§‘ê°’ ë³€í™”ìœ¨ (ì„ )\n",
    "fig_change.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged_sorted['date'],\n",
    "        y=merged_sorted['price_change'],\n",
    "        name='ì§‘ê°’ ë³€í™”ìœ¨(%)',\n",
    "        line=dict(color='#1976D2', width=2),\n",
    "        mode='lines+markers'\n",
    "    ),\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "fig_change.update_layout(\n",
    "    title='ì›”ë³„ ê°ì„± ë³€í™”ëŸ‰ vs ì§‘ê°’ ë³€í™”ìœ¨',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig_change.update_yaxes(title_text=\"ê°ì„± ë³€í™”ëŸ‰\", secondary_y=False)\n",
    "fig_change.update_yaxes(title_text=\"ì§‘ê°’ ë³€í™”ìœ¨ (%)\", secondary_y=True)\n",
    "\n",
    "fig_change.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. êµ¬ë³„ ë¯¼ê°ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "regional_correlation = []\n",
    "\n",
    "for region in REGIONS:\n",
    "    region_sentiment = regional_sentiment[regional_sentiment['region'] == region][['date', 'avg_sentiment']]\n",
    "    region_price = price_df[price_df['region'] == region][['date', 'avg_price']]\n",
    "    \n",
    "    region_merged = pd.merge(region_sentiment, region_price, on='date', how='inner')\n",
    "    \n",
    "    if len(region_merged) >= 5:\n",
    "        corr, p_val = pearsonr(\n",
    "            region_merged['avg_sentiment'].dropna(),\n",
    "            region_merged['avg_price'].dropna()\n",
    "        )\n",
    "        \n",
    "        regional_correlation.append({\n",
    "            'region': region,\n",
    "            'correlation': corr,\n",
    "            'p_value': p_val,\n",
    "            'sensitivity': abs(corr),\n",
    "            'significant': 'âœ…' if p_val < 0.05 else ''\n",
    "        })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(regional_correlation)\n",
    "sensitivity_df = sensitivity_df.sort_values('sensitivity', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š ê°•ë‚¨3êµ¬ ë‰´ìŠ¤ ë¯¼ê°ë„ ë¹„êµ:\")\n",
    "print(sensitivity_df.to_string(index=False))\n",
    "\n",
    "if len(sensitivity_df) > 0:\n",
    "    print(f\"\\nğŸ† ê°€ì¥ ë¯¼ê°í•œ ì§€ì—­: {sensitivity_df.iloc[0]['region']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-1. êµ¬ë³„ íšŒê·€ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# êµ¬ë³„ ìƒì„¸ ë¶„ì„ (íšŒê·€ë¶„ì„)\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š êµ¬ë³„ ê°ì„±-ì§‘ê°’ íšŒê·€ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "regression_results = []\n",
    "\n",
    "for region in REGIONS:\n",
    "    region_sent = regional_sentiment[regional_sentiment['region'] == region]\n",
    "    region_price = price_df[price_df['region'] == region]\n",
    "    \n",
    "    region_data = pd.merge(\n",
    "        region_sent[['date', 'avg_sentiment']],\n",
    "        region_price[['date', 'avg_price']],\n",
    "        on='date',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(region_data) > 5:\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(\n",
    "            region_data['avg_sentiment'],\n",
    "            region_data['avg_price']\n",
    "        )\n",
    "        \n",
    "        regression_results.append({\n",
    "            'region': region,\n",
    "            'r_squared': r_value**2,\n",
    "            'slope': slope,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{region}:\")\n",
    "        print(f\"  RÂ² (ì„¤ëª…ë ¥): {r_value**2:.3f} ({r_value**2*100:.1f}%)\")\n",
    "        print(f\"  ê¸°ìš¸ê¸°: {slope:.3f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}\")\n",
    "        print(f\"  í•´ì„: ê°ì„±ì§€ìˆ˜ 1 ì¦ê°€ ì‹œ ì§‘ê°’ {slope:.2f}ì–µ {'ì¦ê°€' if slope > 0 else 'ê°ì†Œ'}\")\n",
    "\n",
    "# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„\n",
    "regression_df = pd.DataFrame(regression_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™” - RÂ² ë¹„êµ\n",
    "if len(regression_df) > 0:\n",
    "    fig_r2 = px.bar(\n",
    "        regression_df,\n",
    "        x='region',\n",
    "        y='r_squared',\n",
    "        title='êµ¬ë³„ ê°ì„±-ì§‘ê°’ ì„¤ëª…ë ¥ (RÂ²) ë¹„êµ',\n",
    "        text=[f'{r:.1%}' for r in regression_df['r_squared']],\n",
    "        color='r_squared',\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig_r2.update_traces(textposition='outside')\n",
    "    fig_r2.update_layout(template='plotly_white', height=400)\n",
    "    fig_r2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì‹œê°í™”\n",
    "\n",
    "### 9-1. ì´ì¤‘ì¶• ì°¨íŠ¸ (ê°ì„±ì§€ìˆ˜ + ì§‘ê°’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged_df['date'],\n",
    "        y=merged_df['avg_sentiment'],\n",
    "        name=\"ê°ì„±ì§€ìˆ˜\",\n",
    "        line=dict(color='#1976D2', width=2),\n",
    "        hovertemplate='ë‚ ì§œ: %{x}<br>ê°ì„±ì§€ìˆ˜: %{y:.3f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged_df['date'],\n",
    "        y=merged_df['avg_price'],\n",
    "        name=\"í‰ê·  ì§‘ê°’ (ì–µì›)\",\n",
    "        line=dict(color='#D32F2F', width=2),\n",
    "        hovertemplate='ë‚ ì§œ: %{x}<br>ì§‘ê°’: %{y:.2f}ì–µ<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': f'ë‰´ìŠ¤ ê°ì„±ì§€ìˆ˜ vs ê°•ë‚¨3êµ¬ ì§‘ê°’ ì¶”ì´<br><sup>ìƒê´€ê³„ìˆ˜: {corr_sentiment_price:.3f}</sup>',\n",
    "        'x': 0.5\n",
    "    },\n",
    "    xaxis_title=\"ë‚ ì§œ\",\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"ê°ì„±ì§€ìˆ˜\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"ì§‘ê°’ (ì–µì›)\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-2. ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sentiment_dist = news_df.groupby(['year_month', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "monthly_sentiment_dist = monthly_sentiment_dist.div(monthly_sentiment_dist.sum(axis=1), axis=0) * 100\n",
    "monthly_sentiment_dist = monthly_sentiment_dist.reset_index()\n",
    "monthly_sentiment_dist['date'] = monthly_sentiment_dist['year_month'].dt.to_timestamp()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {'ê¸ì •': '#4CAF50', 'ì¤‘ë¦½': '#9E9E9E', 'ë¶€ì •': '#F44336'}\n",
    "\n",
    "for sentiment in ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •']:\n",
    "    if sentiment in monthly_sentiment_dist.columns:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=monthly_sentiment_dist['date'],\n",
    "                y=monthly_sentiment_dist[sentiment],\n",
    "                name=sentiment,\n",
    "                marker_color=colors[sentiment],\n",
    "                hovertemplate=f'{sentiment}: %{{y:.1f}}%<extra></extra>'\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ì›”ë³„ ë‰´ìŠ¤ ê°ì„± ë¶„í¬',\n",
    "    xaxis_title='ë‚ ì§œ',\n",
    "    yaxis_title='ë¹„ìœ¨ (%)',\n",
    "    barmode='stack',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-3. ì‹œì°¨ ìƒê´€ë¶„ì„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "colors = ['#4CAF50' if r > 0 else '#F44336' for r in lag_results['correlation']]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=lag_results['lag'],\n",
    "        y=lag_results['correlation'],\n",
    "        marker_color=colors,\n",
    "        text=[f'{r:.3f}' for r in lag_results['correlation']],\n",
    "        textposition='outside',\n",
    "        hovertemplate='ì‹œì°¨: %{x}ê°œì›”<br>ìƒê´€ê³„ìˆ˜: %{y:.4f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", opacity=0.5)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜ (ê°ì„±ì§€ìˆ˜ â†’ ì§‘ê°’)<br><sup>ì–‘ìˆ˜ ì‹œì°¨ = ê°ì„±ì´ ì§‘ê°’ì— ì„ í–‰</sup>',\n",
    "        'x': 0.5\n",
    "    },\n",
    "    xaxis_title='ì‹œì°¨ (ê°œì›”)',\n",
    "    yaxis_title='ìƒê´€ê³„ìˆ˜',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(tickmode='linear', tick0=-6, dtick=1),\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-4. êµ¬ë³„ ë¯¼ê°ë„ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sensitivity_df) > 0:\n",
    "    fig = px.bar(\n",
    "        sensitivity_df,\n",
    "        x='region',\n",
    "        y='sensitivity',\n",
    "        color='correlation',\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        color_continuous_midpoint=0,\n",
    "        title='êµ¬ë³„ ë‰´ìŠ¤ ë¯¼ê°ë„ (ìƒê´€ê³„ìˆ˜ ì ˆëŒ€ê°’)',\n",
    "        labels={'sensitivity': 'ë¯¼ê°ë„', 'region': 'ì§€ì—­êµ¬', 'correlation': 'ìƒê´€ê³„ìˆ˜'},\n",
    "        text=[f'{s:.3f}' for s in sensitivity_df['sensitivity']]\n",
    "    )\n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        xaxis={'categoryorder': 'total descending'},\n",
    "        height=450\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-5. êµ¬ë³„ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ì‚°ì ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_merged = pd.merge(\n",
    "    regional_sentiment[['date', 'region', 'avg_sentiment']],\n",
    "    price_df[['date', 'region', 'avg_price']],\n",
    "    on=['date', 'region'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    regional_merged,\n",
    "    x='avg_sentiment',\n",
    "    y='avg_price',\n",
    "    color='region',\n",
    "    facet_col='region',\n",
    "    trendline='ols',\n",
    "    title='êµ¬ë³„ ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ê´€ê³„',\n",
    "    labels={'avg_sentiment': 'ê°ì„±ì§€ìˆ˜', 'avg_price': 'ì§‘ê°’ (ì–µì›)', 'region': 'ì§€ì—­êµ¬'},\n",
    "    color_discrete_sequence=['#1976D2', '#388E3C', '#D32F2F']\n",
    ")\n",
    "\n",
    "fig.update_layout(template='plotly_white', showlegend=False, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. í†µí•© ëŒ€ì‹œë³´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'â‘  ê°ì„±ì§€ìˆ˜ vs ì§‘ê°’ ì¶”ì´',\n",
    "        'â‘¡ ì‹œì°¨ë³„ ìƒê´€ê³„ìˆ˜',\n",
    "        'â‘¢ ì›”ë³„ ê°ì„± ë¶„í¬',\n",
    "        'â‘£ êµ¬ë³„ ë¯¼ê°ë„'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"secondary_y\": True}, {}],\n",
    "        [{}, {}]\n",
    "    ],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# â‘  ì´ì¤‘ì¶• ì°¨íŠ¸\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=merged_df['date'], y=merged_df['avg_sentiment'], name='ê°ì„±ì§€ìˆ˜', line=dict(color='#1976D2')),\n",
    "    row=1, col=1, secondary_y=False\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=merged_df['date'], y=merged_df['avg_price'], name='ì§‘ê°’', line=dict(color='#D32F2F')),\n",
    "    row=1, col=1, secondary_y=True\n",
    ")\n",
    "\n",
    "# â‘¡ ì‹œì°¨ ìƒê´€ê³„ìˆ˜\n",
    "lag_colors = ['#4CAF50' if r > 0 else '#F44336' for r in lag_results['correlation']]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=lag_results['lag'], y=lag_results['correlation'], marker_color=lag_colors, showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# â‘¢ ê¸ì •/ë¶€ì • ì¶”ì´\n",
    "for sentiment, color in [('ê¸ì •', '#4CAF50'), ('ë¶€ì •', '#F44336')]:\n",
    "    if sentiment in monthly_sentiment_dist.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=monthly_sentiment_dist['date'],\n",
    "                y=monthly_sentiment_dist[sentiment],\n",
    "                name=sentiment,\n",
    "                line=dict(color=color)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "# â‘£ êµ¬ë³„ ë¯¼ê°ë„\n",
    "if len(sensitivity_df) > 0:\n",
    "    sens_colors = ['#4CAF50' if c > 0 else '#F44336' for c in sensitivity_df['correlation']]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=sensitivity_df['region'], y=sensitivity_df['sensitivity'], marker_color=sens_colors, showlegend=False),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    "    title_text='ğŸ“Š ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    legend=dict(x=1.02, y=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ìµœì¢… ë¶„ì„ ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°€ì¥ ë¯¼ê°í•œ ì§€ì—­\n",
    "if len(sensitivity_df) > 0:\n",
    "    most_sensitive = sensitivity_df.iloc[0]['region']\n",
    "    most_sensitive_corr = sensitivity_df.iloc[0]['correlation']\n",
    "else:\n",
    "    most_sensitive = 'N/A'\n",
    "    most_sensitive_corr = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š ë¶„ì„4: ë‰´ìŠ¤ ê°ì„± ì˜í–¥ ë¶„ì„ - ìµœì¢… ê²°ê³¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ë¶„ì„ ê°œìš”                                                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ ë¶„ì„ ê¸°ê°„: 2023ë…„ 1ì›” ~ 2025ë…„ 12ì›” (3ë…„)                     â”‚\n",
    "â”‚  â€¢ ë¶„ì„ ëŒ€ìƒ: ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬ (ê°•ë‚¨3êµ¬)                    â”‚\n",
    "â”‚  â€¢ ë‰´ìŠ¤ ì¶œì²˜: ì¤‘ì•™ì¼ë³´ ë¶€ë™ì‚° ë‰´ìŠ¤                                â”‚\n",
    "â”‚  â€¢ ë¶„ì„ ê±´ìˆ˜: ë‰´ìŠ¤ {len(news_df):,}ê±´                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  í•µì‹¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€                                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Q1. ê¸ì • ë‰´ìŠ¤ê°€ ë§ìœ¼ë©´ ì§‘ê°’ì´ ì˜¤ë¥´ëŠ”ê°€?                         â”‚\n",
    "â”‚  â†’ ìƒê´€ê³„ìˆ˜: {corr_sentiment_price:.3f}                                            â”‚\"\"\")\n",
    "\n",
    "if corr_sentiment_price > 0.3:\n",
    "    print(\"â”‚  â†’ YES - ì–‘ì˜ ìƒê´€ê´€ê³„ í™•ì¸ (ê¸ì • ë‰´ìŠ¤â†‘ = ì§‘ê°’â†‘)                â”‚\")\n",
    "elif corr_sentiment_price > 0:\n",
    "    print(\"â”‚  â†’ WEAK - ì•½í•œ ì–‘ì˜ ìƒê´€ê´€ê³„                                    â”‚\")\n",
    "else:\n",
    "    print(\"â”‚  â†’ NO - ìŒì˜ ìƒê´€ê´€ê³„ ë˜ëŠ” ê´€ê³„ì—†ìŒ                             â”‚\")\n",
    "\n",
    "print(f\"\"\"â”‚                                                                 â”‚\n",
    "â”‚  Q2. ë°˜ì‘ ì†ë„ëŠ” ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?                                  â”‚\n",
    "â”‚  â†’ ìµœì  ì‹œì°¨: {int(best_lag['lag'])}ê°œì›”                                            â”‚\n",
    "â”‚  â†’ ë‰´ìŠ¤ ê°ì„±ì´ {int(best_lag['lag'])}ê°œì›” í›„ ì§‘ê°’ì— ê°€ì¥ í¬ê²Œ ë°˜ì˜                  â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  Q3. ì–´ëŠ êµ¬ê°€ ë‰´ìŠ¤ì— ê°€ì¥ ë¯¼ê°í•œê°€?                             â”‚\n",
    "â”‚  â†’ {most_sensitive} (ìƒê´€ê³„ìˆ˜: {most_sensitive_corr:.3f})                            â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  êµ¬ë³„ ë¯¼ê°ë„ ìˆœìœ„                                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\"\"\")\n",
    "\n",
    "for i, row in sensitivity_df.iterrows():\n",
    "    rank = list(sensitivity_df.index).index(i) + 1\n",
    "    print(f\"â”‚  {rank}ìœ„: {row['region']} (ìƒê´€ê³„ìˆ˜: {row['correlation']:.3f}, ë¯¼ê°ë„: {row['sensitivity']:.3f})     â”‚\")\n",
    "\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ì‹œì‚¬ì  ë° í™œìš©ë°©ì•ˆ                                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  1. ë¶€ë™ì‚° ì‹œì¥ ì˜ˆì¸¡ ì§€í‘œ                                        â”‚\n",
    "â”‚     â†’ ë‰´ìŠ¤ ê°ì„±ì§€ìˆ˜ë¥¼ ì„ í–‰ì§€í‘œë¡œ í™œìš© ê°€ëŠ¥                       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  2. íˆ¬ì ì˜ì‚¬ê²°ì • ì°¸ê³                                            â”‚\n",
    "â”‚     â†’ ê¸ì • ë‰´ìŠ¤ ì¦ê°€ ì‹œ {int(best_lag['lag'])}ê°œì›” í›„ ê°€ê²© ìƒìŠ¹ ì˜ˆìƒ                 â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  3. ì§€ì—­ë³„ ì°¨ë³„í™” ì „ëµ                                           â”‚\n",
    "â”‚     â†’ {most_sensitive}ëŠ” ë‰´ìŠ¤ì— ë¯¼ê°, ë¹ ë¥¸ ëŒ€ì‘ í•„ìš”                     â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ë¶„ì„ì˜ í•œê³„ì                                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  1. ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„                                          â”‚\n",
    "â”‚     â†’ ë‰´ìŠ¤ê°€ ì§‘ê°’ì— ì˜í–¥ vs ì§‘ê°’ì´ ë‰´ìŠ¤ì— ì˜í–¥ êµ¬ë¶„ ì–´ë ¤ì›€       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  2. í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„±ë¶„ì„ì˜ í•œê³„                                   â”‚\n",
    "â”‚     â†’ ë¬¸ë§¥ ê³ ë ¤ ëª»í•¨ (ì˜ˆ: \"ìƒìŠ¹ì„¸ êº¾ì—¬\" = ë¶€ì •ì  ì˜ë¯¸)           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  3. ë‹¨ì¼ ë§¤ì²´ ë¶„ì„                                               â”‚\n",
    "â”‚     â†’ ì¤‘ì•™ì¼ë³´ë§Œ ë¶„ì„, ë‹¤ë¥¸ ë§¤ì²´ í¬í•¨ ì‹œ ê²°ê³¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ     â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ ê²°ê³¼ CSV ì €ì¥\n",
    "output_path = '../data/analysis_results/'\n",
    "import os\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# ì›”ë³„ ê°ì„±ì§€ìˆ˜ ì €ì¥\n",
    "monthly_sentiment.to_csv(f'{output_path}monthly_sentiment.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# êµ¬ë³„ ë¯¼ê°ë„ ì €ì¥\n",
    "sensitivity_df.to_csv(f'{output_path}regional_sensitivity.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì‹œì°¨ ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "lag_results.to_csv(f'{output_path}lag_analysis.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ë‰´ìŠ¤ ê°ì„± ê²°ê³¼ ì €ì¥\n",
    "news_df.to_csv(f'{output_path}news_with_sentiment.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# íšŒê·€ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "if len(regression_df) > 0:\n",
    "    regression_df.to_csv(f'{output_path}regression_results.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"   ì €ì¥ ìœ„ì¹˜: {output_path}\")\n",
    "print(f\"\\n   ì €ì¥ëœ íŒŒì¼:\")\n",
    "print(f\"   - monthly_sentiment.csv (ì›”ë³„ ê°ì„±ì§€ìˆ˜)\")\n",
    "print(f\"   - regional_sensitivity.csv (êµ¬ë³„ ë¯¼ê°ë„)\")\n",
    "print(f\"   - lag_analysis.csv (ì‹œì°¨ ë¶„ì„ ê²°ê³¼)\")\n",
    "print(f\"   - news_with_sentiment.csv (ë‰´ìŠ¤ ê°ì„± ê²°ê³¼)\")\n",
    "print(f\"   - regression_results.csv (íšŒê·€ë¶„ì„ ê²°ê³¼)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
